{"cells":[{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["from datetime import datetime\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import pandas as pd\n","import seaborn as sns\n","from IPython.display import HTML, display\n","\n","from scipy import stats\n","\n","sns.set()\n","\n",""]},{"cell_type":"markdown","metadata":{},"source":["## Import outcomes dataset and tidy up"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["df = pd.read_csv(\"data/jp_outcomes.csv\")\n","\n",""]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["# Convert floats to ints to make reporting easier\n","numerics = [\"float64\"]\n","for col in df.select_dtypes(include=numerics).columns:\n","    if df[col].isnull().sum() == 0:\n","        # print(col)\n","        df[col] = df[col].astype(\"int\")\n","# for col in df.columns:\n","#     print(col)\n",""]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["periods = pd.PeriodIndex(start=\"2016Q1\", end=\"2017Q4\", freq=\"Q\")\n","period_list = list(periods.strftime(\"%YQ%q\"))\n","periods_len = len(period_list)\n","\n","for i, period in enumerate(reversed(period_list)):\n","\n","    df[period] = df[\"Group\" + str(periods_len - i)].str[:1]\n","    cat_map = {\"T\": 1, \"C\": 0, \"0\": -1}\n","    df[period] = df[period].map(cat_map)\n","    if i > 0:\n","        later_periods = period_list[-i:]\n","        df.loc[df[period] == 1, later_periods] = -2\n","    # df[period] = df[period].fillna(-1)\n","    # df[period] = df[period].astype('int')"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["numeric_cols = [\n","    col for col in df.columns.tolist() if col.startswith((\"earn_\", \"sw_pay_\"))\n","]\n",""]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":"2016Q1  2016Q2  2016Q3  2016Q4  2017Q1  2017Q2  2017Q3  2017Q4\n 1      -2      -2      -2      -2      -2      -2      -2         5581\n 0       1      -2      -2      -2      -2      -2      -2         8309\n         0       1      -2      -2      -2      -2      -2         9015\n                 0       1      -2      -2      -2      -2         7687\n                         0       1      -2      -2      -2         4393\n                                 0       1      -2      -2         2668\n                                         0       1      -2         1832\n                                                 0       1         2028\n                                                         0         8110\n                                                        -1         1342\n                                                -1      -1         2433\n                                        -1      -1      -1         3402\n                                -1      -1      -1      -1         4782\n                        -1      -1      -1      -1      -1         6947\n                -1      -1      -1      -1      -1      -1        11527\n        -1      -1      -1      -1      -1      -1      -1        14292\n-1      -1      -1      -1      -1      -1      -1      -1        15787\nName: id, dtype: int64"},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["grouped = df.groupby(period_list)[\"id\"].count()\n","grouped.sort_index(ascending=False, inplace=True)\n","grouped\n","\n",""]},{"cell_type":"markdown","metadata":{},"source":["## Add weights\n","This is just a global sort but needs to be replaced by a per-group classification function\n","called at the start of the binning/weighting code"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["# Sort all records\n","df = df.set_index(\n","    [\n","        # 'cluster',\n","        \"earn_tot_mean_1315\",\n","        \"sw_pay_mean_1315\",\n","        \"duration_days_0\",\n","        \"id\",\n","    ]\n",")\n","df.sort_index(inplace=True)\n","df.reset_index(inplace=True)\n","df.index.name = \"rank\"\n","# # np.sum(df1.index.duplicated())\n","df.reset_index(inplace=True)\n","df.set_index(\"id\", inplace=True)\n",""]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["\n",""]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["def add_weights(df, period):\n","    # 1. Create scores\n","    # Currently done above with global ranks but need to replace\n","\n","    # 2. Create bins based on scores\n","    # Create a temporary df for T and C groups\n","    df_T = df.loc[df[period] == 1].copy()\n","    df_C = df.loc[df[period] == 0].copy()\n","\n","    # Split T group into equal sized bins\n","    df_T[\"bin\"], bins = pd.qcut(df_T[\"rank\"], 100, retbins=True, labels=False)\n","\n","    # Put C group into T bins based on T bin edges\n","    df_C[\"bin\"] = pd.cut(df_C[\"rank\"], bins, labels=range(len(bins) - 1))\n","\n","    # Exclude unassigned C group members to eliminate outliers\n","    df_C = df_C.dropna(subset=[\"bin\"])\n","    df_C[\"bin\"] = df_C[\"bin\"].astype(\"int\")\n","\n","    # 3. Add weights based on bins\n","    # Create counts for T and C by bin\n","    t_bin_counts = pd.Series(df_T.groupby(\"bin\")[\"rank\"].count(), name=\"t_bin_counts\")\n","    c_bin_counts = pd.Series(df_C.groupby(\"bin\")[\"rank\"].count(), name=\"c_bin_counts\")\n","    bin_counts = pd.concat([t_bin_counts, c_bin_counts], axis=\"columns\")\n","\n","    # Divide T by C to get weights for C group\n","    bin_counts[\"weight\"] = bin_counts[\"t_bin_counts\"] / bin_counts[\"c_bin_counts\"]\n","    # c_total = df_C.shape[0]\n","    # t_total = df_T.shape[0]\n","    # bin_counts[\"weight\"] = bin_counts[\"abs_weight\"] * c_total / t_total\n","\n","    # All Ts have weight = 1\n","    df_T[\"weight\"] = 1\n","\n","    # Assign C weights based on weights in bin_counts dataframe\n","    # Have to reset and then set index to avoid losing it!\n","    df_C = df_C.reset_index()\n","    df_C = df_C.merge(bin_counts[[\"weight\"]], how=\"inner\", on=\"bin\")\n","    df_C = df_C.set_index(\"id\")\n","\n","    # Append T and C dataframes together\n","    out_df = df_T.append(df_C)\n","\n","    # Select columns to return\n","    return_cols = [\"weight\", \"bin\"]\n","    out_df = out_df[return_cols]\n","\n","    # Create multiindex for consistency with groups and counterfactuals\n","    columns = pd.MultiIndex.from_product(\n","        [[period], return_cols, [\"_\"], [\"_\"]],\n","        names=[\"period\", \"data_type\", \"cf_cutoff\", \"cf_period\"],\n","    )\n","    out_df.columns = columns\n","\n","    # Finally ready!\n","    print(f\"\\n------------------\\nPeriod: {period}\")\n","    print(f\"T group size:     {df_T['weight'].sum()}\")\n","    print(f\"Sum of C weights: {df_C['weight'].sum()}\")\n","    return out_df\n","\n",""]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"\n------------------\nPeriod: 2016Q1\nT group size:     5581\nSum of C weights: 5581.0\n"},{"name":"stdout","output_type":"stream","text":"\n------------------\nPeriod: 2016Q2\nT group size:     8309\nSum of C weights: 8309.0\n"},{"name":"stdout","output_type":"stream","text":"\n------------------\nPeriod: 2016Q3\nT group size:     9015\nSum of C weights: 9015.0\n"},{"name":"stdout","output_type":"stream","text":"\n------------------\nPeriod: 2016Q4\nT group size:     7687\nSum of C weights: 7687.0\n"},{"name":"stdout","output_type":"stream","text":"\n------------------\nPeriod: 2017Q1\nT group size:     4393\nSum of C weights: 4393.0\n"},{"name":"stdout","output_type":"stream","text":"\n------------------\nPeriod: 2017Q2\nT group size:     2668\nSum of C weights: 2668.0\n"},{"name":"stdout","output_type":"stream","text":"\n------------------\nPeriod: 2017Q3\nT group size:     1832\nSum of C weights: 1832.0\n"},{"name":"stdout","output_type":"stream","text":"\n------------------\nPeriod: 2017Q4\nT group size:     2028\nSum of C weights: 2028.0\n"}],"source":["# Create dedicated dataframe for groups, weights, bins, counterfactuals\n","# Start with periods...\n","w_df = df[period_list]\n","\n","# Add multiindex...\n","columns = pd.MultiIndex.from_product(\n","    [list(w_df.columns), [\"group\"], [\"_\"], [\"_\"]],\n","    names=[\"period\", \"data_type\", \"cf_cutoff\", \"cf_period\"],\n",")\n","w_df.columns = columns\n","\n","# Then add weights and bins...\n","for i, period in enumerate(period_list):\n","    w_df = pd.concat([w_df, add_weights(df, period)], axis=\"columns\", sort=False)\n",""]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["\n",""]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"\n---------\nThis period: 2016Q1\n"},{"name":"stdout","output_type":"stream","text":"Later period: 2016Q2\nGroup name: 0 8309.000000000002\nGroup name: 1 8309.0\nLater period: 2016Q3\nGroup name: 0 9015.0\nGroup name: 1 9015.0\nLater period: 2016Q4\nGroup name: 0 7687.0\nGroup name: 1 7687.0\n"},{"name":"stdout","output_type":"stream","text":"Later period: 2017Q1\nGroup name: 0 4393.0\nGroup name: 1 4393.0\nLater period: 2017Q2\nGroup name: 0 2668.0\nGroup name: 1 2668.0\nLater period: 2017Q3\nGroup name: 0 1832.0\nGroup name: 1 1832.0\nLater period: 2017Q4\nGroup name: 0"},{"name":"stdout","output_type":"stream","text":" 2028.0\nGroup name: 1 2028.0\n\n---------\nThis period: 2016Q2\nLater period: 2016Q3\nGroup name: 0 9015.0\nGroup name: 1 9015.0\nLater period: 2016Q4\nGroup name: 0 7687.0\nGroup name: 1 7687.0\n"},{"name":"stdout","output_type":"stream","text":"Later period: 2017Q1\nGroup name: 0 4393.0\nGroup name: 1 4393.0\nLater period: 2017Q2\nGroup name: 0 2668.0\nGroup name: 1 2668.0\nLater period: 2017Q3\nGroup name: 0 1832.0\nGroup name: 1 1832.0\nLater period: 2017Q4\nGroup name: 0 2028.0\nGroup name: 1 2028.0\n\n---------\nThis period: 2016Q3\n"},{"name":"stdout","output_type":"stream","text":"Later period: 2016Q4\nGroup name: 0 7687.0\nGroup name: 1 7687.0\nLater period: 2017Q1\nGroup name: 0 4393.0\nGroup name: 1 4393.0\nLater period: 2017Q2\nGroup name: 0 2668.0\nGroup name: 1 2668.0\nLater period: 2017Q3"},{"name":"stdout","output_type":"stream","text":"\nGroup name: 0 1832.0\nGroup name: 1 1832.0\nLater period: 2017Q4\nGroup name: 0 2028.0\nGroup name: 1 2028.0\n\n---------\nThis period: 2016Q4\nLater period: 2017Q1\nGroup name: 0 4393.0\nGroup name: 1 4393.0\nLater period: 2017Q2\nGroup name: 0 2668.0\nGroup name: 1 "},{"name":"stdout","output_type":"stream","text":"2668.0\nLater period: 2017Q3\nGroup name: 0 1832.0\nGroup name: 1 1832.0\nLater period: 2017Q4\nGroup name: 0 2028.0\nGroup name: 1 2028.0\n\n---------\nThis period: 2017Q1\nLater period: 2017Q2\nGroup name: 0 2668.0\nGroup name: 1 2668.0\nLater period: 2017Q3\nGroup name: 0 1832.0\nGroup name: 1 1832.0\nLater period: 2017Q4\nGroup name: 0 2028.0\nGroup name: 1"},{"name":"stdout","output_type":"stream","text":" 2028.0\n\n---------\nThis period: 2017Q2\nLater period: 2017Q3\nGroup name: 0 1832.0\nGroup name: 1 1832.0\nLater period: 2017Q4\nGroup name: 0 2028.0\nGroup name: 1 2028.0\n\n---------\nThis period: 2017Q3\nLater period: 2017Q4\nGroup name: 0 2028.0\nGroup name: 1 2028.0\n"}],"source":["# Create counterfactual weights\n","# As the ox ploughs!\n","# First, go forwards, adding CF weight columns for each period\n","for i, this_period in enumerate(period_list[:-1]):\n","\n","    this_group = (this_period, \"group\", \"_\", \"_\")\n","    this_bin = (this_period, \"bin\", \"_\", \"_\")\n","    this_real_weight = (this_period, \"weight\", \"_\", \"_\")\n","\n","    later_period_list = period_list[i + 1 :]\n","    print(f\"\\n---------\\nThis period: {this_period}\")\n","    for j, later_period in enumerate(later_period_list):\n","        later_group = (later_period, \"group\", \"_\", \"_\")\n","        later_bin = (later_period, \"bin\", \"_\", \"_\")\n","        later_real_weight = (later_period, \"weight\", \"_\", \"_\")\n","\n","        this_later_df = pd.DataFrame(\n","            w_df[\n","                (w_df[this_group] == 0)\n","                & (w_df[later_group].isin([1, 0]))\n","            ]\n","        )\n","        this_later_df = this_later_df[[this_period, later_period]]\n","        g_this_later_df = this_later_df.groupby([later_group])\n","        print(f\"Later period: {later_period}\")\n","        for name, group in g_this_later_df:\n","            print(f\"Group name: {name}\", group[later_real_weight].sum())\n","\n","        # g_later_group_this_bin = this_later_df.groupby([later_group, this_bin])\n","\n","        # for name, group in g_later_group_this_bin:\n","        #     print(name)\n","\n","\n","# column_index = w_df.columns.get_loc((\"2016Q2\", \"abs_weight\", \"_\", \"_\"))\n","\n","# w_df.loc[\n","#     (w_df[(\"2016Q1\", \"group\", \"_\", \"_\")] == 0) & (w_df[(\"2016Q2\", \"group\", \"_\", \"_\")]\n","#     == 1)\n","# ].describe()\n","\n","# .groupby((\"2016Q1\", \"bin\", \"_\", \"_\"))[column_index].sum()\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}