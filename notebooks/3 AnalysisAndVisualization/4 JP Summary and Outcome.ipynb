{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, event\n",
    "import urllib.parse\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs & Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL database\n",
    "server = 'CSKMA0400\\RDB_Data'\n",
    "db = 'JLDJobPath'\n",
    "odbc_connection_string = 'DRIVER={SQL Server Native Client 11.0};SERVER='+server+';DATABASE='+db+';Trusted_Connection=yes'\n",
    "\n",
    "# Unique ID variable for sql tables\n",
    "uid_var = 'ppsn'\n",
    "\n",
    "# Input sql tables\n",
    "clusters_sql_tables = [\n",
    "                       'linkedclaims_casuals_2018m04_v2_flat_20140401_with_income_36Vars__7BGM_full_clusters',\n",
    "                       'linkedclaims_casuals_2018m04_v2_flat_20140701_with_income_36Vars__7BGM_full_clusters',\n",
    "                       'linkedclaims_casuals_2018m04_v2_flat_20141001_with_income_36Vars__7BGM_full_clusters',\n",
    "                       'linkedclaims_casuals_2018m04_v2_flat_20150101_with_income_36Vars__7BGM_full_clusters',\n",
    "                       'linkedclaims_casuals_2018m04_v2_flat_20150401_with_income_36Vars__7BGM_full_clusters',\n",
    "                       'linkedclaims_casuals_2018m04_v2_flat_20150701_with_income_36Vars__7BGM_full_clusters',\n",
    "                       'linkedclaims_casuals_2018m04_v2_flat_20151001_with_income_36Vars__7BGM_full_clusters',\n",
    "                       'linkedclaims_casuals_2018m04_v2_flat_20160101_with_income_36Vars__7BGM_full_clusters',\n",
    "                       'linkedclaims_casuals_2018m04_v2_flat_20160401_with_income_36Vars__7BGM_full_clusters',\n",
    "                       'linkedclaims_casuals_2018m04_v2_flat_20160701_with_income_36Vars__7BGM_full_clusters'\n",
    "                       ]\n",
    "\n",
    "flat_jld_sql_tables = [\n",
    "                       'linkedclaims_casuals_2018m04_v2_flat_20140401_with_income',\n",
    "                       'linkedclaims_casuals_2018m04_v2_flat_20140701_with_income',\n",
    "                       'linkedclaims_casuals_2018m04_v2_flat_20141001_with_income',\n",
    "                       'linkedclaims_casuals_2018m04_v2_flat_20150101_with_income',\n",
    "                       'linkedclaims_casuals_2018m04_v2_flat_20150401_with_income',\n",
    "                       'linkedclaims_casuals_2018m04_v2_flat_20150701_with_income',\n",
    "                       'linkedclaims_casuals_2018m04_v2_flat_20151001_with_income',\n",
    "                       'linkedclaims_casuals_2018m04_v2_flat_20160101_with_income',\n",
    "                       'linkedclaims_casuals_2018m04_v2_flat_20160401_with_income',\n",
    "                       'linkedclaims_casuals_2018m04_v2_flat_20160701_with_income'\n",
    "                       ]\n",
    "fjld_variable_age = 'age'\n",
    "fjld_variable_durationdays0 = 'duration_days_0'\n",
    "fjld_variable_hist_lr0 = 'hist_lr_0'\n",
    "fjld_variable_occupation0 = 'occupation_0'\n",
    "fjld_variable_sex = 'sex'\n",
    "fjld_variable_tdurationdays = 'total_duration_days'\n",
    "fjld_variable_sum_pflag = 'total_sum_penaltyflag'\n",
    "flat_jld_selected_variables = [uid_var, \n",
    "                               fjld_variable_age,\n",
    "                                fjld_variable_durationdays0,\n",
    "                               fjld_variable_hist_lr0,\n",
    "                               fjld_variable_occupation0,\n",
    "                               fjld_variable_sex,\n",
    "                               fjld_variable_tdurationdays,\n",
    "                               fjld_variable_sum_pflag]\n",
    "\n",
    "jld_sql_table = 'linkedclaims_casuals_2018m04_v2'\n",
    "jld_variable_event_start = 'StartDate'\n",
    "jld_variable_event_end = 'EndDate'\n",
    "jld_variable_event_type = 'hist_lr'\n",
    "# jld_variable_previus_event_type = 'PrevLR'\n",
    "# jld_variable_next_event_type = 'NextLR'\n",
    "# jld_variable_last_claim = 'LastClaim'\n",
    "jld_variable_last_lr = 'LastLR'\n",
    "jld_variable_lr_flag = 'lr_flag'\n",
    "jld_variable_hist_lls = 'hist_lls'\n",
    "# jld_variable_first_lls = 'FirstLLS'\n",
    "# jld_variable_last_lls = 'LastLLS'\n",
    "jld_variable_occupation_rank = 'occupation_rank'\n",
    "jld_variable_LM_code_rank = 'LM_code_rank'\n",
    "jld_variable_ada_code_rank = 'ada_code_rank'\n",
    "jld_variable_family_flag_rank = 'family_flag_rank'\n",
    "jld_variable_marital_status_rank = 'marital_status_rank'\n",
    "jld_selected_variables = [uid_var,\n",
    "                          jld_variable_event_start,\n",
    "                          jld_variable_event_end,\n",
    "                          jld_variable_event_type,\n",
    "#                           jld_variable_previus_event_type,\n",
    "#                           jld_variable_next_event_type,\n",
    "#                           jld_variable_last_claim,\n",
    "                          jld_variable_last_lr,\n",
    "                          jld_variable_lr_flag,\n",
    "                          jld_variable_hist_lls,\n",
    "#                           jld_variable_first_lls,\n",
    "#                           jld_variable_last_lls,\n",
    "                          jld_variable_occupation_rank,\n",
    "                          jld_variable_LM_code_rank,\n",
    "                          jld_variable_ada_code_rank,\n",
    "                          jld_variable_family_flag_rank,\n",
    "                          jld_variable_marital_status_rank]\n",
    "\n",
    "\n",
    "# Referral data\n",
    "data_path = '//cskma0294/F/Evaluations/JobPath/Python/Data/ReferralData/'\n",
    "referral_data_filename_csv_1 = data_path+'Data for Evaluation Run 23072018 V3.csv'\n",
    "referral_data_filename_csv_2 = data_path+'2017 Data for Evaluation 04092018.csv'\n",
    "referral_data_csvfilenames = [referral_data_filename_csv_1, referral_data_filename_csv_2]\n",
    "rd_date_fields = ['Start Date','Date of Interview','PPP Agreed Date','Date of Cancellation','End Date','Date_paused','Dateresumed']\n",
    "rd_date_format = '%d/%m/%Y'\n",
    "rd_string_fields = ['Amended Referral Status','Paused_reason','Reason for Cancellation','Referal Status Description','Local Office Name', 'Cancellationsubcategory' ]\n",
    "rd_start_date_var = 'Start Date'\n",
    "rd_interview_date_var = 'Date of Interview'\n",
    "rd_end_date_var = 'End Date'\n",
    "rd_pause_date_var = 'Date_paused'\n",
    "rd_resume_date_var = 'Dateresumed'\n",
    "rd_paused_reason_var = 'Paused_reason'\n",
    "rd_cancellation_date_var = 'Date of Cancellation'\n",
    "rd_cancellation_reason_var = 'Reason for Cancellation'\n",
    "rd_referral_status_var = 'Referal Status Description'\n",
    "rd_uid_var = 'Pps No'\n",
    "\n",
    "# Referral data rollup/dups remove flag vars\n",
    "referral_status_target = 'Completed'\n",
    "previous_jp_completed_flag_var = 'prev_jp_completed'\n",
    "\n",
    "# Analysis parameters\n",
    "analysis_date_start_strings = [\n",
    "                               '20140401',\n",
    "                               '20140701',\n",
    "                               '20141001',\n",
    "                               '20150101',\n",
    "                               '20150401',\n",
    "                               '20150701',\n",
    "                               '20151001',\n",
    "                               '20160101',\n",
    "                               '20160401',\n",
    "                               '20160701'\n",
    "                               ]\n",
    "analysis_date_end_strings =   [\n",
    "                               '20160401',\n",
    "                               '20160401',\n",
    "                               '20161001',\n",
    "                               '20170101',\n",
    "                               '20170401',\n",
    "                               '20170701',\n",
    "                               '20171001',\n",
    "                               '20180101',\n",
    "                               '20180401',\n",
    "                               '20180701'\n",
    "                               ]\n",
    "analysis_dates_string_format = '%Y%m%d'\n",
    "\n",
    "number_of_periods = 16\n",
    "periods_lenght_month = 3\n",
    "\n",
    "# Output analysis elegible by period\n",
    "jp_prefix_elegible_var = 'jp_elegible'\n",
    "jp_eligible_target_var = fjld_variable_durationdays0\n",
    "jp_eligible_target_var_min_val = 10*30\n",
    "\n",
    "# Output analysis started jp by period\n",
    "jp_prefx_started_var = 'jp_started'\n",
    "jp_prefx_started_target_var = rd_interview_date_var\n",
    "\n",
    "# Output Analysis: imputed end date\n",
    "imputed_ph1_end_date_var = 'imputed_ph1_end_date'\n",
    "imputed_ph1_end_date_offset_months = 12\n",
    "\n",
    "# Output Analysis fields summary within the analysis window\n",
    "analysis_start_date_var = 'analysis_start_date'\n",
    "analysis_end_date_var = 'analysis_end_date'\n",
    "days_in_treatment_in_aw_var = 'jp_days_in_aw'\n",
    "days_before_streatment_start_in_aw_var = 'jp_referral_days_in_aw'\n",
    "days_paused_in_aw_var = 'jp_paused_days_in_aw'\n",
    "jobpath_flag_in_aw_var = 'jp_flag_in_aw'\n",
    "cancellation_flag_in_aw_var = 'cancelled_flag_in_aw'\n",
    "paused_flag_in_aw_var = 'paused_flag_in_aw'\n",
    "jp_started_before_aw_completed_ph1_in_aw_var = 'jp_started_before_aw_completed_ph1_in_aw'\n",
    "jp_started_in_aw_completed_ph1_after_aw_var = 'jp_started_in_aw_completed_ph1_after_aw'\n",
    "jp_ph1_completed_in_aw_firstQ_year2_var = 'jp_ph1_completed_in_aw_firstQ_year2_var'\n",
    "firstQ_year2_offset_month_min = 12\n",
    "firstQ_year2_offset_month_max = 15\n",
    "jp_ph1_completed_in_aw_secondQ_year2_var = 'jp_ph1_completed_in_aw_secondQ_year2_var'\n",
    "secondQ_year2_offset_month_min = 15\n",
    "secondQ_year2_offset_month_max = 18\n",
    "jp_ph1_completed_in_aw_thirdQ_year2_var = 'jp_ph1_completed_in_aw_thirdQ_year2_var'\n",
    "thirdQ_year2_offset_month_min = 18\n",
    "thirdQ_year2_offset_month_max = 21\n",
    "jp_ph1_completed_in_aw_fourthQ_year2_var = 'jp_ph1_completed_in_aw_fourthQ_year2_var'\n",
    "fourthQ_year2_offset_month_min = 21\n",
    "fourthQ_year2_offset_month_max = 24\n",
    "jp_ph1_not_completed_in_aw_var = 'jp_ph1_not_completed_in_aw'\n",
    "jp_cancelled_before_start_in_aw_var = 'jp_cancelled_before_start_in_aw'\n",
    "jp_cancelled_in_aw_start_before_aw_var = 'jp_cancelled_in_aw_start_before_aw'\n",
    "jp_cancelled_in_aw_start_in_aw_var = 'jp_cancelled_in_aw_start_in_aw_var'\n",
    "jp_cancelled_afer_aw_start_in_aw_var = 'jp_cancelled_afer_aw_start_in_aw'\n",
    "\n",
    "# Output Analysis fields: summary before the analysis window\n",
    "jobpath_flag_before_aw_var = 'jp_flag_before_aw'\n",
    "cancellation_flag_before_aw_var = 'cancelled_flag_before_aw'\n",
    "paused_flag_before_aw_var = 'paused_flag_before_aw'\n",
    "completed_ph1_jp_before_aw_var = 'completed_ph1_jp_before_aw'\n",
    "\n",
    "# Output Analysis fields: summary after the analysis window\n",
    "jobpath_flag_after_aw_var = 'jp_flag_after_aw'\n",
    "started_jp_after_aw_var = 'started_jp_after_aw'\n",
    "\n",
    "# Output Post Processing Fields:\n",
    "jobpath_category_in_aw_var = 'jobpath_category_in_aw'\n",
    "\n",
    "# Output suffix\n",
    "upload_to_sql = False\n",
    "export_to_csv = True\n",
    "out_suffix = '_jp_summary_status'\n",
    "csv_path = '//cskma0294/F/Evaluations/JobPath/Python/Analysis/JPOutcomes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(iterable, n = 1):\n",
    "    current_batch = []\n",
    "    for item in iterable:\n",
    "        current_batch.append(item)\n",
    "        if len(current_batch) == n:\n",
    "            yield current_batch\n",
    "            current_batch = []\n",
    "    if current_batch:\n",
    "        yield current_batch\n",
    "\n",
    "def read_data_from_sql(sql_table):\n",
    "    # Connect to SQL\n",
    "    params = urllib.parse.quote_plus(odbc_connection_string)\n",
    "    engine = create_engine('mssql+pyodbc:///?odbc_connect=%s' % params)\n",
    "    conn = engine.connect().connection\n",
    "\n",
    "    @event.listens_for(engine, 'before_cursor_execute')\n",
    "    def receive_before_cursor_execute(conn, cursor, statement, params, context, executemany):\n",
    "        if executemany:\n",
    "            cursor.fast_executemany = True\n",
    "\n",
    "    df = pd.read_sql_table(sql_table, engine)\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "def upload_df_to_sql(df, sql_table):\n",
    "    # Load into SQL\n",
    "    # Connect to SQL\n",
    "    params = urllib.parse.quote_plus(odbc_connection_string)\n",
    "    engine = create_engine('mssql+pyodbc:///?odbc_connect=%s' % params)\n",
    "    conn = engine.connect().connection\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # SpeedUp For fast execution of mutiple row \n",
    "    @event.listens_for(engine, 'before_cursor_execute')\n",
    "    def receive_before_cursor_execute(conn, cursor, statement, params, context, executemany):\n",
    "        if executemany:\n",
    "            cursor.fast_executemany = True\n",
    "\n",
    "    # Drop table if exists\n",
    "    sql_string_drop = \"IF OBJECT_ID('\"+ sql_table + \"', 'U') IS NOT NULL\" +'\\n'+ \"DROP TABLE \" + sql_table\n",
    "    cursor.execute(sql_string_drop)\n",
    "    conn.commit()\n",
    "    \n",
    "    #upload data\n",
    "    print('\\nUploading to SQL')\n",
    "    sql_chunksize = 10000\n",
    "    df.to_sql(sql_table, engine, if_exists='append', index=False, chunksize=sql_chunksize)\n",
    "    #Close SQL Connection\n",
    "    conn.close()\n",
    "    \n",
    "def remove_dups_in_referral_data(df):\n",
    "    data = df.copy()\n",
    "    \n",
    "    data [previous_jp_completed_flag_var] = 0\n",
    "    data = data.sort_values(uid_var)\n",
    "    dups = data.duplicated(subset=uid_var, keep=False)\n",
    "    \n",
    "    res = data[dups == False]\n",
    "    dups = data[dups == True]\n",
    "    \n",
    "    uids = dups[uid_var].tolist()\n",
    "    batch_size = len(uids)/20\n",
    "    for batch_uids in batch(uids, n=batch_size):\n",
    "        batch_dups = dups.loc[dups[uid_var].isin(batch_uids)]\n",
    "        grp_data = batch_dups.groupby(uid_var)\n",
    "        for uid, group in grp_data:\n",
    "            if (pd.isna(uid) == 0  & pd.isnull(uid) == 0):\n",
    "                mygroup = group.sort_values([rd_start_date_var,\n",
    "                                             rd_pause_date_var,\n",
    "                                             rd_resume_date_var,\n",
    "                                             rd_cancellation_date_var,\n",
    "                                             rd_end_date_var], \n",
    "                                            ascending = [False,\n",
    "                                                         False,\n",
    "                                                         False,\n",
    "                                                         False,\n",
    "                                                         False])\n",
    "                to_append = mygroup.iloc[0].copy()\n",
    "                to_check = mygroup[1:]\n",
    "                if len( to_check.loc[to_check[rd_referral_status_var] == referral_status_target] > 1 ) :\n",
    "                       to_append[previous_jp_completed_flag_var] = 1\n",
    "\n",
    "                res = res.append(to_append)\n",
    "    return res\n",
    "\n",
    "def assign_status(df, status_source_col, status_target_col):\n",
    "    # Status assignment rules:\n",
    "    #     'UBCO' -> \"On Live Register - Credits only\", \n",
    "    #     'UBSEMPCAS|UBSST|UBSTEA|UASEMP|UABTWE|UABTWP|DABTWP|UAPTJI' -> \"Employment/Self-employment supported by DSP\", \n",
    "    #     'C-UA|UACAS|UASPRICAS|UAPTEOCAS|UAOFPXCAS' -> \"On Live Register (casual worker) - JA\",\n",
    "    #     'C-UB|UBCAS|UBPTEOCAS' -> \"On Live Register (casual worker) - JB\",\n",
    "    #     'UAINTN|UAMOM|UATLO|UAWPG' -> \"In Education, Training or Employment Placement Course\", \n",
    "    #     'UAFASS|UAFISH|FISH' -> \"Closed off the Live Register for other reasons\",\n",
    "    #     'UA' - > \"On Live Register (excluding casual workers) - JA\",\n",
    "    #     'UB' - > \"On Live Register (excluding casual workers) - JB\",\n",
    "    #     'SST|STEA|SEMP|BTW|BTWFD|PTJI|FIS' -> \"Employment/Self-employment supported by DSP\",\n",
    "    #     'DUPS|OFP|OFPJST|OFPLPSSJST|OFPL|OFPS|OFPU|OFPJ|PRTA|FASS|UAFASS' -> \"Closed off the Live Register for other reasons\",\n",
    "    #     'CE|FAS|ICTP|INTN|UAINTN|LMAF|LMEF|WPGO|MOM|SPFT|ES|TLO|SLO' -> \"In Education, Training or Employment Placement Course\", \n",
    "    #     'EMPL' -> \"In employment\"\n",
    "    \n",
    "    data = df.copy()\n",
    "    \n",
    "    conditions = [ ~(data[status_source_col].str.contains('CL', regex=True)) & (data[status_source_col].str.contains('UA|UB', regex=True)) & ((data[status_source_col].str.contains('UBCO', regex=True))),\n",
    "                   ~(data[status_source_col].str.contains('CL', regex=True)) & (data[status_source_col].str.contains('UA|UB', regex=True)) & ((data[status_source_col].str.contains('UBSEMPCAS|UBSST|UBSTEA|UASEMP|UABTWE|UABTWP|DABTWP|UAPTJI', regex=True))),\n",
    "                   ~(data[status_source_col].str.contains('CL', regex=True)) & (data[status_source_col].str.contains('UA|UB', regex=True)) & ((data[status_source_col].str.contains('C-UA|UACAS|UASPRICAS|UAPTEOCAS|UAOFPXCAS', regex=True))),\n",
    "                   ~(data[status_source_col].str.contains('CL', regex=True)) & (data[status_source_col].str.contains('UA|UB', regex=True)) & ((data[status_source_col].str.contains('C-UB|UBCAS|UBPTEOCAS', regex=True))),\n",
    "                   ~(data[status_source_col].str.contains('CL', regex=True)) & (data[status_source_col].str.contains('UA|UB', regex=True)) & ((data[status_source_col].str.contains('UAINTN|UAMOM|UATLO|UAWPG', regex=True))),\n",
    "                   ~(data[status_source_col].str.contains('CL', regex=True)) & (data[status_source_col].str.contains('UA|UB', regex=True)) & ((data[status_source_col].str.contains('UAFASS|UAFISH|FISH', regex=True))),\n",
    "                   ~(data[status_source_col].str.contains('CL', regex=True)) & (data[status_source_col].str.contains('UA|UB', regex=True)) & ((data[status_source_col].str.contains('UA', regex=True))),\n",
    "                   ~(data[status_source_col].str.contains('CL', regex=True)) & (data[status_source_col].str.contains('UA|UB', regex=True)) & ((data[status_source_col].str.contains('UB', regex=True))),\n",
    "                   ~(data[status_source_col].str.contains('CL', regex=True)) & ~(data[status_source_col].str.contains('UA|UB', regex=True))  & (data[status_source_col].str.contains('SST|STEA|SEMP|BTW|BTWFD|PTJI|FIS', regex=True)), \n",
    "                   ~(data[status_source_col].str.contains('CL', regex=True)) & ~(data[status_source_col].str.contains('UA|UB', regex=True))  & (data[status_source_col].str.contains('DUPS|OFP|OFPJST|OFPLPSSJST|OFPL|OFPS|OFPU|OFPJ|PRTA|FASS|UAFASS', regex=True)),\n",
    "                   ~(data[status_source_col].str.contains('CL', regex=True)) & ~(data[status_source_col].str.contains('UA|UB', regex=True))  & (data[status_source_col].str.contains('CE|FAS|ICTP|INTN|UAINTN|LMAF|LMEF|WPGO|MOM|SPFT|ES|TLO|SLO', regex=True)),\n",
    "                   ~(data[status_source_col].str.contains('CL', regex=True)) & ~(data[status_source_col].str.contains('UA|UB', regex=True))  & ~(data[status_source_col].str.contains('EMPL', regex=True)),\n",
    "                   ~(data[status_source_col].str.contains('CL', regex=True)) & ~(data[status_source_col].str.contains('UA|UB', regex=True))  & (data[status_source_col].str.contains('SST|STEA|SEMP|BTW|BTWFD|PTJI|FIS|DUPS|OFP|OFPJST|OFPLPSSJST|OFPL|OFPS|OFPU|OFPJ|PRTA|FASS|UAFASS|CE|FAS|ICTP|INTN|UAINTN|LMAF|LMEF|WPGO|MOM|SPFT|ES|TLO|SLO|EMPL', regex=True)),\n",
    "                   (data[status_source_col] != ' ')                    \n",
    "                 ]\n",
    "\n",
    "\n",
    "    choices_four = [\"On Live Register\", \n",
    "                    \"In employment\", \n",
    "                    \"On Live Register\", \n",
    "                    \"On Live Register\", \n",
    "                    \"In Education, Training or Employment Placement Course\", \n",
    "                    \"Closed off the Live Register for other reasons\", \n",
    "                    \"On Live Register\", \n",
    "                    \"On Live Register\", \n",
    "                    \"In employment\", \n",
    "                    \"Closed off the Live Register for other reasons\",  \n",
    "                    \"In Education, Training or Employment Placement Course\", \n",
    "                    \"In employment\", \n",
    "                    \"Closed off the Live Register for other reasons\", \n",
    "                    data[status_source_col]]\n",
    "\n",
    "    data[status_target_col+'_simple'] = np.select(conditions, choices_four, \"Closed off the Live Register for other reasons\")\n",
    "\n",
    "\n",
    "    choices_det = [\"On Live Register - Credits only\", \n",
    "                   \"Employment/Self-employment supported by DSP\", \n",
    "                   \"On Live Register (casual worker) - JA\", \n",
    "                   \"On Live Register (casual worker) - JB\", \n",
    "                   \"In Education, Training or Employment Placement Course\", \n",
    "                   \"Closed off the Live Register for other reasons\", \n",
    "                   \"On Live Register (excluding casual workers) - JA\", \n",
    "                   \"On Live Register (excluding casual workers) - JB\", \n",
    "                   \"Employment/Self-employment supported by DSP\", \n",
    "                   \"Closed off the Live Register for other reasons\", \n",
    "                  \"In Education, Training or Employment Placement Course\", \n",
    "                   \"In employment\", \n",
    "                   data[status_target_col+'_simple'], \n",
    "                   data[status_target_col+'_simple'] ]\n",
    "\n",
    "    data[status_target_col] = np.select(conditions, choices_det, data[status_target_col+'_simple'])\n",
    "               \n",
    "    return data\n",
    "\n",
    "def query_jld(variable_uid, uids, jld_sql_table, select_variables, date_var = None, min_date = None, max_date = None):\n",
    "    # Connect to SQL\n",
    "    params = urllib.parse.quote_plus(odbc_connection_string)\n",
    "    engine = create_engine('mssql+pyodbc:///?odbc_connect=%s' % params)\n",
    "    conn = engine.connect().connection\n",
    "\n",
    "    @event.listens_for(engine, 'before_cursor_execute')\n",
    "    def receive_before_cursor_execute(conn, cursor, statement, params, context, executemany):\n",
    "        if executemany:\n",
    "            cursor.fast_executemany = True\n",
    "    \n",
    "    sql_query_string = \"SELECT \" + (',').join(select_variables) + \" FROM \" + jld_sql_table + \\\n",
    "                        \" WHERE \" +variable_uid+ \" IN \" + str(uids) \n",
    "\n",
    "    data = pd.read_sql_query(sql_query_string, engine)\n",
    "    \n",
    "    # Close SQL connection\n",
    "    conn.close()\n",
    "    \n",
    "    return data\n",
    "\n",
    "def select_rows_in_date(df, date, variable_min_date = None, variable_max_date = None):\n",
    "    res = df.copy()\n",
    "    if variable_min_date is not None and variable_max_date is not None:\n",
    "        res = res.loc[(df[variable_min_date] < date) & (df[variable_max_date] > date)]\n",
    "    elif variable_min_date is not None:\n",
    "        res = res.loc[(df[variable_min_date] < date)]\n",
    "    elif variable_max_date is not None:\n",
    "        res = res.loc[(df[variable_max_date] > date)]\n",
    "    \n",
    "    return res\n",
    "\n",
    "def check_jld (df, quarter_start, quarter_end, suffix):\n",
    "#     start_time = time.time()\n",
    "    res = df.copy()\n",
    "    \n",
    "    uids = res[uid_var].tolist()\n",
    "    \n",
    "    batch_dfs = []\n",
    "    batch_size = 10000\n",
    "    jld_data = pd.DataFrame()\n",
    "    for batch_uids in batch(uids, n=batch_size):\n",
    "        mybatch_uids = tuple(batch_uids)\n",
    "        batch_data = query_jld(uid_var, mybatch_uids, jld_sql_table, jld_selected_variables)\n",
    "        batch_dfs.extend(batch_data.to_dict('records'))\n",
    "    jld_data = pd.DataFrame(batch_dfs)\n",
    "#     print (jld_data)\n",
    "#     print ('Batch query done')\n",
    "#     elapsed_time = time.time() - start_time\n",
    "#     print ('Elapsed time: '+ time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "    \n",
    "    jld_data = select_rows_in_date(df=jld_data, \n",
    "                                   date=quarter_end, \n",
    "                                   variable_min_date=jld_variable_event_start)\n",
    "#     print ('Select rows done')\n",
    "#     elapsed_time = time.time() - start_time\n",
    "#     print ('Elapsed time: '+ time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "    \n",
    "    batch_dfs = []\n",
    "    batch_size = 5000\n",
    "#     print (\"N Batches = %d\" %(len(uids)/batch_size))\n",
    "    for batch_uids in batch(uids, n=batch_size):\n",
    "        batch_jld_data = jld_data.loc[jld_data[uid_var].isin(batch_uids)]\n",
    "        grp_data = batch_jld_data.groupby(uid_var)\n",
    "\n",
    "        for uid, group in grp_data:\n",
    "            mygroup = group.sort_values([jld_variable_event_end, \n",
    "                                         jld_variable_lr_flag,\n",
    "                                         jld_variable_event_type, \n",
    "                                         jld_variable_event_start], \n",
    "                                        ascending = [False,False,False,False])\n",
    "            batch_dfs.append(mygroup.iloc[0].to_dict())\n",
    "    \n",
    "    jld_data_single = pd.DataFrame(batch_dfs)\n",
    "    \n",
    "#     print ('Single row JLD done')\n",
    "#     elapsed_time = time.time() - start_time\n",
    "#     print ('Elapsed time: '+ time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "    \n",
    "#     print ('Attach status')\n",
    "    jld_data_single = assign_status(jld_data_single, jld_variable_last_lr, 'status')\n",
    "#     elapsed_time = time.time() - start_time\n",
    "#     print ('Elapsed time: '+ time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "    \n",
    "#     print (jld_data_single)\n",
    "    \n",
    "#     print (jld_data_single.columns)\n",
    "    # Renane JLD cols before joining info\n",
    "    cols_name = jld_data_single.columns\n",
    "    for cname in cols_name:\n",
    "        if cname != uid_var:\n",
    "            jld_data_single.rename(columns={cname:str(cname)+suffix}, inplace=True)\n",
    "    \n",
    "    # Join info\n",
    "    res = pd.merge(res, jld_data_single, on=uid_var, how='left')\n",
    "    \n",
    "    # Set to 0 'lr_flag' for ppsn not in JLD at date\n",
    "    res[jld_variable_lr_flag+suffix].fillna(0, inplace=True)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def summarise_data_after_aw(df, end_analysis_window_date):\n",
    "    res = df.copy()\n",
    "    \n",
    "    ## set jobpath flag after analysis window\n",
    "    res [jobpath_flag_after_aw_var] = 0\n",
    "    \n",
    "    # if date start > analysis end, and date start exists\n",
    "    res.loc[(pd.isna(res[rd_end_date_var]) == 0) &\n",
    "            (res[rd_start_date_var] > end_analysis_window_date),\n",
    "            jobpath_flag_after_aw_var] = 1\n",
    "    # if date end > analysis end, and date end exists\n",
    "    res.loc[(pd.isna(res[rd_end_date_var]) == 0) &\n",
    "            (res[rd_end_date_var] > end_analysis_window_date),\n",
    "            jobpath_flag_after_aw_var] = 1\n",
    "    \n",
    "    ## set started_jp_after_aw_var\n",
    "    res [started_jp_after_aw_var] = 0\n",
    "    # if rd_interview_date_var exists\n",
    "    res.loc[(pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (res[rd_interview_date_var] > end_analysis_window_date),\n",
    "            started_jp_after_aw_var ] = 1\n",
    "    \n",
    "    return res\n",
    "        \n",
    "    \n",
    "def summarise_data_before_aw(df, start_analysis_window_date):\n",
    "    res = df.copy()\n",
    "    \n",
    "    ## set cancelled flag before analysis window\n",
    "    res[cancellation_flag_before_aw_var] = 0\n",
    "    # if cancellation date defined and before analysis window\n",
    "    res.loc[(pd.isna(res[rd_cancellation_date_var]) == 0) &\n",
    "            (res[rd_cancellation_date_var] <  analysis_date_start),\n",
    "            cancellation_flag_before_aw_var] = 1\n",
    "    # if cancellation date not defined, cancellation reason defined and start date before analysis window\n",
    "    res.loc[(pd.isna(res[rd_cancellation_date_var]) == 1) &\n",
    "            (pd.isna(res[rd_cancellation_reason_var]) == 0) &\n",
    "            (res[rd_start_date_var] < analysis_date_start),\n",
    "            cancellation_flag_before_aw_var] = 1\n",
    "    # if cancellation date not defined, cancellation reason defined and start date not defined\n",
    "    res.loc[(pd.isna(res[rd_cancellation_date_var]) == 1) &\n",
    "            (pd.isna(res[rd_cancellation_reason_var]) == 0) &\n",
    "            (pd.isna(res[rd_start_date_var]) == 1),\n",
    "            cancellation_flag_in_aw_var] = np.nan\n",
    "    \n",
    "    # set pause flag before analysis window\n",
    "    res [paused_flag_before_aw_var] = 0\n",
    "    # if resume date present and before analysis start\n",
    "    res.loc[(pd.isna(res[rd_resume_date_var]) == 0) & \n",
    "            (res[rd_resume_date_var] <= analysis_date_start),\n",
    "            paused_flag_before_aw_var] = 1\n",
    "    \n",
    "    ## set jobpath flag before analysis window\n",
    "    res [jobpath_flag_before_aw_var] = 0\n",
    "    # if date end < analysis start, and date end exists\n",
    "    res.loc[(pd.isna(res[rd_end_date_var]) == 0) &\n",
    "            (res[rd_end_date_var] < start_analysis_window_date),\n",
    "            jobpath_flag_before_aw_var] = 1\n",
    "    # if paused before analysis window\n",
    "    res.loc[res[paused_flag_before_aw_var] == 1,\n",
    "           jobpath_flag_before_aw_var] = 1\n",
    "    # if cancelled before analysis window\n",
    "    res.loc[res[cancellation_flag_before_aw_var] == 1,\n",
    "           jobpath_flag_before_aw_var] = 1\n",
    "    \n",
    "    ## set completed_ph1_jp_before_aw_var\n",
    "    res[completed_ph1_jp_before_aw_var] = 0\n",
    "    # if date end exists and < analysis start\n",
    "    res.loc[(pd.isna(res[imputed_ph1_end_date_var]) == 0) &\n",
    "            (res[imputed_ph1_end_date_var] < start_analysis_window_date), \n",
    "            completed_ph1_jp_before_aw_var] = 1\n",
    "            \n",
    "    return res\n",
    "\n",
    "\n",
    "def summarise_data_in_aw(df, start_analysis_window_date, end_analysis_window_date):\n",
    "    res = df.copy()\n",
    "    \n",
    "    res [analysis_start_date_var] = start_analysis_window_date\n",
    "    res [analysis_end_date_var] = end_analysis_window_date\n",
    "    \n",
    "    \n",
    "    ## set jp_started_before_aw_completed_in_aw_var\n",
    "    res[jp_started_before_aw_completed_ph1_in_aw_var] = 0\n",
    "    res.loc[(pd.isna(rd_interview_date_var) == 0) &\n",
    "            (pd.isna(imputed_ph1_end_date_var) == 0) &\n",
    "            (res[rd_interview_date_var] < analysis_date_start) &\n",
    "            (res[imputed_ph1_end_date_var] >= analysis_date_start) &\n",
    "            (res[imputed_ph1_end_date_var] <= analysis_date_end), \n",
    "            jp_started_before_aw_completed_ph1_in_aw_var ] = 1\n",
    "    \n",
    "    ## set jp_started_in_aw_completed_ph1_after_aw_var\n",
    "    res[jp_started_in_aw_completed_ph1_after_aw_var] = 0\n",
    "    res.loc[(pd.isna(rd_interview_date_var) == 0) &\n",
    "            (pd.isna(imputed_ph1_end_date_var) == 0) &\n",
    "            (res[rd_interview_date_var] >= analysis_date_start) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_end) &\n",
    "            (res[imputed_ph1_end_date_var] > analysis_date_end), \n",
    "            jp_started_in_aw_completed_ph1_after_aw_var ] = 1\n",
    "    \n",
    "    ## set jp_ph1_completed_in_aw_firstQ_year2_var\n",
    "    res[jp_ph1_completed_in_aw_firstQ_year2_var] = 0\n",
    "    res.loc[(pd.isna(imputed_ph1_end_date_var) == 0) &\n",
    "            (res[imputed_ph1_end_date_var] > analysis_date_start + DateOffset(months=firstQ_year2_offset_month_min)) & \n",
    "            (res[imputed_ph1_end_date_var] <= analysis_date_start + DateOffset(months=firstQ_year2_offset_month_max)), \n",
    "            jp_ph1_completed_in_aw_firstQ_year2_var] = 1\n",
    "    \n",
    "    ## set jp_ph1_completed_in_aw_secondQ_year2_var\n",
    "    res[jp_ph1_completed_in_aw_secondQ_year2_var] = 0\n",
    "    res.loc[(pd.isna(imputed_ph1_end_date_var) == 0) &\n",
    "            (res[imputed_ph1_end_date_var] > analysis_date_start + DateOffset(months=secondQ_year2_offset_month_min)) & \n",
    "            (res[imputed_ph1_end_date_var] <= analysis_date_start + DateOffset(months=secondQ_year2_offset_month_max)), \n",
    "            jp_ph1_completed_in_aw_secondQ_year2_var] = 1\n",
    "    \n",
    "    ## set jp_ph1_completed_in_aw_thirdQ_year2_var\n",
    "    res[jp_ph1_completed_in_aw_thirdQ_year2_var] = 0\n",
    "    res.loc[(pd.isna(imputed_ph1_end_date_var) == 0) &\n",
    "            (res[imputed_ph1_end_date_var] > analysis_date_start + DateOffset(months=thirdQ_year2_offset_month_min)) & \n",
    "            (res[imputed_ph1_end_date_var] <= analysis_date_start + DateOffset(months=thirdQ_year2_offset_month_max)), \n",
    "            jp_ph1_completed_in_aw_thirdQ_year2_var] = 1\n",
    "    \n",
    "    ## set jp_ph1_completed_in_aw_thirdQ_year2_var\n",
    "    res[jp_ph1_completed_in_aw_fourthQ_year2_var] = 0\n",
    "    res.loc[(pd.isna(imputed_ph1_end_date_var) == 0) &\n",
    "            (res[imputed_ph1_end_date_var] > analysis_date_start + DateOffset(months=fourthQ_year2_offset_month_min)) & \n",
    "            (res[imputed_ph1_end_date_var] <= analysis_date_start + DateOffset(months=fourthQ_year2_offset_month_max)), \n",
    "            jp_ph1_completed_in_aw_fourthQ_year2_var] = 1\n",
    "    \n",
    "    ## set jp_ph1_not_completed_in_aw_var\n",
    "    res[jp_ph1_not_completed_in_aw_var] = 0\n",
    "    res.loc[(res[jp_ph1_completed_in_aw_firstQ_year2_var] == 0) &\n",
    "            (res[jp_ph1_completed_in_aw_secondQ_year2_var] == 0) &\n",
    "            (res[jp_ph1_completed_in_aw_thirdQ_year2_var] == 0) &\n",
    "            (res[jp_ph1_completed_in_aw_fourthQ_year2_var] == 0),\n",
    "            jp_ph1_not_completed_in_aw_var] = 1\n",
    "    \n",
    "        \n",
    "    ## set jobpath flag in analysis window\n",
    "    res[jobpath_flag_in_aw_var] = 0\n",
    "    #if start date in analysis window\n",
    "    res.loc[(pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (res[rd_start_date_var] >= analysis_date_start) &\n",
    "            (res[rd_start_date_var] <= analysis_date_end),\n",
    "            jobpath_flag_in_aw_var] = 1\n",
    "    #if interview date in analysis window\n",
    "    res.loc[(pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (res[rd_interview_date_var] >= analysis_date_start) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_end),\n",
    "            jobpath_flag_in_aw_var] = 1\n",
    "    #if end date in analysis window\n",
    "    res.loc[(pd.isna(res[rd_end_date_var]) == 0) &\n",
    "            (res[rd_end_date_var] >= analysis_date_start) &\n",
    "            (res[rd_end_date_var] <= analysis_date_end),\n",
    "            jobpath_flag_in_aw_var] = 1\n",
    "    #if start date < analysis start and end date > analysis end\n",
    "    res.loc[(pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (res[rd_start_date_var] <= analysis_date_start) &\n",
    "            (pd.isna(res[rd_end_date_var]) == 0) &\n",
    "            (res[rd_end_date_var] >= analysis_date_end),\n",
    "            jobpath_flag_in_aw_var] = 1\n",
    "    #if start date < analysis start , cacellation > analysis start\n",
    "    res.loc[(pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (res[rd_start_date_var] <= analysis_date_start) &\n",
    "            (pd.isna(res[rd_cancellation_date_var]) == 0) &\n",
    "            (res[rd_cancellation_date_var] >= analysis_date_end),\n",
    "            jobpath_flag_in_aw_var] = 1\n",
    "    #if start date < analysis start , pause > analysis start\n",
    "    res.loc[(pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (res[rd_start_date_var] <= analysis_date_start) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (res[rd_pause_date_var] >= analysis_date_end),\n",
    "            jobpath_flag_in_aw_var] = 1\n",
    "            \n",
    "    \n",
    "    ## set cancelled flag in analysis window\n",
    "    res[cancellation_flag_in_aw_var] = 0\n",
    "    # if cancellation date defined and within analysis window\n",
    "    res.loc[(pd.isna(res[rd_cancellation_date_var]) == 0) &\n",
    "            (res[rd_cancellation_date_var] >=  analysis_date_start) &\n",
    "            (res[rd_cancellation_date_var] <=  analysis_date_end),\n",
    "            cancellation_flag_in_aw_var] = 1\n",
    "    # if cancellation date not defined, cancelaltion reason defined and start date within analysis window\n",
    "    res.loc[(pd.isna(res[rd_cancellation_date_var]) == 1) &\n",
    "            (pd.isna(res[rd_cancellation_reason_var]) == 0) &\n",
    "            (res[rd_start_date_var] >=  analysis_date_start) &\n",
    "            (res[rd_start_date_var] <=  analysis_date_end),\n",
    "            cancellation_flag_in_aw_var] = 1\n",
    "    # if cancellation date not defined, cancelaltion reason defined and start date not defined\n",
    "    res.loc[(pd.isna(res[rd_cancellation_date_var]) == 1) &\n",
    "            (pd.isna(res[rd_cancellation_reason_var]) == 0) &\n",
    "            (pd.isna(res[rd_start_date_var]) == 1),\n",
    "            cancellation_flag_in_aw_var] = np.nan\n",
    "    \n",
    "    ## set jp_cancelled_before_start_in_aw_var\n",
    "    res [jp_cancelled_before_start_in_aw_var] = 0\n",
    "    res.loc[(res[cancellation_flag_in_aw_var] == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var])) == 1,\n",
    "            jp_cancelled_before_start_in_aw_var] = 1\n",
    "    \n",
    "    ## set jp_cancelled_in_aw_start_before_aw_var\n",
    "    res [jp_cancelled_in_aw_start_before_aw_var] = 0\n",
    "    res.loc[(pd.isna(rd_cancellation_date_var)== 0) &\n",
    "            (pd.isna(rd_interview_date_var)== 0) &\n",
    "            (res[rd_cancellation_date_var] >= analysis_date_start) &\n",
    "            (res[rd_cancellation_date_var] <= analysis_date_end) &\n",
    "            (res[rd_interview_date_var] < analysis_date_start),\n",
    "            jp_cancelled_in_aw_start_before_aw_var] = 1\n",
    "    \n",
    "    ## set jp_cancelled_in_aw_start_in_aw_var\n",
    "    res[jp_cancelled_in_aw_start_in_aw_var] = 0\n",
    "    res.loc[(pd.isna(rd_cancellation_date_var)== 0) &\n",
    "            (pd.isna(rd_interview_date_var)== 0) &\n",
    "            (res[rd_cancellation_date_var] >= analysis_date_start) &\n",
    "            (res[rd_cancellation_date_var] <= analysis_date_end) &\n",
    "            (res[rd_interview_date_var] >= analysis_date_start) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_end), \n",
    "            jp_cancelled_in_aw_start_in_aw_var] = 1\n",
    "    \n",
    "    ## set jp_cancelled_afer_aw_start_in_aw_var\n",
    "    res[jp_cancelled_afer_aw_start_in_aw_var] = 0\n",
    "    res.loc[(pd.isna(rd_cancellation_date_var)== 0) &\n",
    "            (pd.isna(rd_interview_date_var)== 0) &\n",
    "            (res[rd_cancellation_date_var] >= analysis_date_end) &\n",
    "            (res[rd_interview_date_var] >= analysis_date_start) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_end), \n",
    "            jp_cancelled_afer_aw_start_in_aw_var] = 1\n",
    "    \n",
    "    ## set paused flag in analysis window\n",
    "    res [paused_flag_in_aw_var] = 0\n",
    "    # if pause date present and within analysis start/end\n",
    "    res.loc[(pd.isna(res[rd_pause_date_var]) == 0) & \n",
    "            (res[rd_pause_date_var] <= analysis_date_end) & \n",
    "            (res[rd_pause_date_var] >= analysis_date_start),\n",
    "            paused_flag_in_aw_var] = 1\n",
    "    # if pause date present and <= analysis start and resume date present and >= analysis start\n",
    "    res.loc[(pd.isna(res[rd_pause_date_var]) == 0) & \n",
    "            (res[rd_pause_date_var] <= analysis_date_start) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) & \n",
    "            (res[rd_resume_date_var] >= analysis_date_start),\n",
    "            paused_flag_in_aw_var] = 1\n",
    "    # if pause date present and <= analysis start and resume date not present\n",
    "    res.loc[(pd.isna(res[rd_pause_date_var]) == 0) & \n",
    "            (res[rd_pause_date_var] <= analysis_date_start) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 1) ,\n",
    "            paused_flag_in_aw_var] = 1\n",
    "    \n",
    "    \n",
    "    ## count days paused in analysis window\n",
    "    res[days_paused_in_aw_var] = 0\n",
    "    # if missing pause date\n",
    "    res.loc[ (res[paused_flag_in_aw_var] == 1) & (pd.isna(res[rd_pause_date_var]) == 1), days_paused_in_aw_var] = np.nan\n",
    "    # if paused and pause date >= analysis start and resume <= analysis end \n",
    "    res.loc[(res[paused_flag_in_aw_var] == 1) & \n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) & \n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (res[rd_pause_date_var] >= analysis_date_start) &\n",
    "            (res[rd_resume_date_var] <= analysis_date_end),\n",
    "            days_paused_in_aw_var] = (res[rd_resume_date_var] - res[rd_pause_date_var]).dt.days\n",
    "    # if paused and pause date >= analysis start and resume >= analysis end \n",
    "    res.loc[(res[paused_flag_in_aw_var] == 1) & \n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) & \n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (res[rd_pause_date_var] >= analysis_date_start) &\n",
    "            (res[rd_resume_date_var] >= analysis_date_end),\n",
    "            days_paused_in_aw_var] = ( res [analysis_end_date_var] - res[rd_pause_date_var]).dt.days\n",
    "    # if paused and pause date <= analysis start and resume <= analysis end \n",
    "    res.loc[(res[paused_flag_in_aw_var] == 1) & \n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) & \n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (res[rd_pause_date_var] <= analysis_date_start) &\n",
    "            (res[rd_resume_date_var] <= analysis_date_end),\n",
    "            days_paused_in_aw_var] = (res[rd_resume_date_var] - res [analysis_start_date_var]).dt.days\n",
    "    # if paused and pause date <= analysis start and resume >= analysis end \n",
    "    res.loc[(res[paused_flag_in_aw_var] == 1) & \n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) & \n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (res[rd_pause_date_var] <= analysis_date_start) &\n",
    "            (res[rd_resume_date_var] >= analysis_date_end),\n",
    "            days_paused_in_aw_var] = (res[analysis_end_date_var] - res [analysis_start_date_var]).dt.days\n",
    "    # if paused and pause date <= analysis start and resume date not defined\n",
    "    res.loc[(res[paused_flag_in_aw_var] == 1) & \n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) & \n",
    "            (pd.isna(res[rd_resume_date_var]) == 1) &\n",
    "            (res[rd_pause_date_var] <= analysis_date_start),\n",
    "            days_paused_in_aw_var] = ( res[analysis_end_date_var] - res [analysis_start_date_var]).dt.days\n",
    "    # if paused and pause date >= analysis start and resume&end date not defined \n",
    "    # if analysis start <= pause date <= analysis end \n",
    "    res.loc[(res[paused_flag_in_aw_var] == 1) & \n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) & \n",
    "            (pd.isna(res[rd_resume_date_var]) == 1) &\n",
    "            (pd.isna(res[rd_end_date_var]) == 1) &\n",
    "            (res[rd_pause_date_var] >= analysis_date_start),\n",
    "            days_paused_in_aw_var] = ( res [analysis_end_date_var] - res[rd_pause_date_var]).dt.days\n",
    "    # if paused and pause date >= analysis start and resume not defined \n",
    "    # if analysis start <= pause date <= analysis end <= end date\n",
    "    res.loc[(res[paused_flag_in_aw_var] == 1) & \n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) & \n",
    "            (pd.isna(res[rd_resume_date_var]) == 1) &\n",
    "            (pd.isna(res[rd_end_date_var]) == 0) &\n",
    "            (res[rd_pause_date_var] >= analysis_date_start) &\n",
    "            (res[rd_pause_date_var] <= analysis_date_end) & \n",
    "            (analysis_date_end <= res[rd_end_date_var]),\n",
    "            days_paused_in_aw_var] = ( res [analysis_end_date_var] - res[rd_pause_date_var]).dt.days\n",
    "    # if paused and pause date >= analysis start and resume not defined \n",
    "    # if analysis start <= pause date <= end date <= analysis end \n",
    "    res.loc[(res[paused_flag_in_aw_var] == 1) & \n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) & \n",
    "            (pd.isna(res[rd_resume_date_var]) == 1) &\n",
    "            (pd.isna(res[rd_end_date_var]) == 0) &\n",
    "            (res[rd_pause_date_var] >= analysis_date_start) &\n",
    "            (res[rd_pause_date_var] <= res[rd_end_date_var]) & \n",
    "            (res[rd_end_date_var] <= analysis_date_end ),\n",
    "            days_paused_in_aw_var] = ( res [rd_end_date_var] - res[rd_pause_date_var]).dt.days\n",
    "\n",
    "    \n",
    "    ## count days in referral in analysis window\n",
    "    res[days_before_streatment_start_in_aw_var] = 0\n",
    "    # if start date and interview date not defined\n",
    "    res.loc[(pd.isna(res[rd_start_date_var]) == 1) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 1),\n",
    "            days_before_streatment_start_in_aw_var] = np.nan\n",
    "    # if start date defined, within analysis window and interview date not defined\n",
    "    res.loc[(pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (res[rd_start_date_var] >= analysis_date_start) &\n",
    "            (res[rd_start_date_var] <= analysis_date_end) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 1),\n",
    "            days_before_streatment_start_in_aw_var] = np.nan\n",
    "    # if start date defined, <= analysis window start and interview date not defined\n",
    "    res.loc[(pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (res[rd_start_date_var] <= analysis_date_start) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 1),\n",
    "            days_before_streatment_start_in_aw_var] = np.nan\n",
    "    # if not paused\n",
    "    # if start date defined, within analysis window and interview date within analysis window\n",
    "    res.loc[(res[paused_flag_in_aw_var]== 0) &\n",
    "            (pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (res[rd_start_date_var] >= analysis_date_start) &\n",
    "            (res[rd_start_date_var] <= analysis_date_end) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) & \n",
    "            (res[rd_interview_date_var] >= analysis_date_start) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_end),\n",
    "            days_before_streatment_start_in_aw_var] = (res[rd_interview_date_var] - res[rd_start_date_var]).dt.days\n",
    "    # if not paused\n",
    "    # if start date defined, within analysis window and interview date >= analysis window end\n",
    "    res.loc[(res[paused_flag_in_aw_var]== 0) &\n",
    "            (pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (res[rd_start_date_var] >= analysis_date_start) &\n",
    "            (res[rd_start_date_var] <= analysis_date_end) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) & \n",
    "            (res[rd_interview_date_var] >= analysis_date_end),\n",
    "            days_before_streatment_start_in_aw_var] = (res[analysis_end_date_var] - res[rd_start_date_var]).dt.days\n",
    "    # if not paused\n",
    "    # if start date defined, <= analysis window start and interview date within analysis window\n",
    "    res.loc[(res[paused_flag_in_aw_var]== 0) &\n",
    "            (pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (res[rd_start_date_var] <= analysis_date_start) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) & \n",
    "            (res[rd_interview_date_var] >= analysis_date_start) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_end),\n",
    "            days_before_streatment_start_in_aw_var] = (res[rd_interview_date_var] - res[analysis_start_date_var]).dt.days\n",
    "    # if not paused\n",
    "    # if start date defined, <= analysis window start and interview date >= analysis window\n",
    "    res.loc[(res[paused_flag_in_aw_var]== 0) &\n",
    "            (pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (res[rd_start_date_var] <= analysis_date_start) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) & \n",
    "            (res[rd_interview_date_var] >= analysis_date_end),\n",
    "            days_before_streatment_start_in_aw_var] = (res[analysis_end_date_var] - res[analysis_start_date_var]).dt.days\n",
    "    # if paused\n",
    "    # if start date <= pause date <= analysis start <= analysis end  <= resume date <= interview date\n",
    "    res.loc[(res[paused_flag_in_aw_var]== 1) &\n",
    "            (pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (res[rd_pause_date_var] <= analysis_date_start) &\n",
    "            (res[rd_resume_date_var] >= analysis_date_end),\n",
    "            days_before_streatment_start_in_aw_var] = 0\n",
    "    # if paused\n",
    "    # if start date <= pause date <= analysis start <= analysis end , resume date not defined\n",
    "    res.loc[(res[paused_flag_in_aw_var]== 1) &\n",
    "            (pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 1) &\n",
    "            (res[rd_pause_date_var] <= analysis_date_start),\n",
    "            days_before_streatment_start_in_aw_var] = 0\n",
    "    \n",
    "    # if paused\n",
    "    # if start date <= analysis start  <= pause date <= analysis end <= resume date <= interview date \n",
    "    res.loc[(res[paused_flag_in_aw_var]== 1) &\n",
    "            (pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (res[rd_start_date_var] <= analysis_date_start) &\n",
    "            (analysis_date_start <= res[rd_pause_date_var]) &\n",
    "            (analysis_date_end <= res[rd_resume_date_var]),\n",
    "            days_before_streatment_start_in_aw_var] = (res[rd_pause_date_var] - res[analysis_start_date_var]).dt.days\n",
    "    # if paused\n",
    "    # if start date <= analysis start  <= pause date <= analysis end, resume date not defined, interview date defined\n",
    "    res.loc[(res[paused_flag_in_aw_var]== 1) &\n",
    "            (pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 1) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (res[rd_start_date_var] <= analysis_date_start) &\n",
    "            (analysis_date_start <= res[rd_pause_date_var]),\n",
    "            days_before_streatment_start_in_aw_var] = (res[rd_pause_date_var] - res[analysis_start_date_var]).dt.days\n",
    "    # if paused\n",
    "    # if analysis start <= start date <= pause date <= analysis end <= resume date <= interview date \n",
    "    res.loc[(res[paused_flag_in_aw_var]== 1) &\n",
    "            (pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (analysis_date_start <= res[rd_start_date_var]) &\n",
    "            (res[rd_start_date_var] <= res[rd_pause_date_var] ) &\n",
    "            (res[rd_pause_date_var] <= analysis_date_end) &\n",
    "            (analysis_date_end <= res[rd_resume_date_var]),\n",
    "            days_before_streatment_start_in_aw_var] = (res[rd_pause_date_var] - res[rd_start_date_var]).dt.days\n",
    "    # if paused\n",
    "    # if  analysis start <= start date <= pause date <= analysis end, resume date not defined, interview date defined\n",
    "    res.loc[(res[paused_flag_in_aw_var]== 1) &\n",
    "            (pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 1) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (analysis_date_start <= res[rd_start_date_var]) &\n",
    "            (res[rd_start_date_var] <= res[rd_pause_date_var] ) &\n",
    "            (res[rd_pause_date_var] <= analysis_date_end),\n",
    "            days_before_streatment_start_in_aw_var] = (res[rd_pause_date_var] - res[rd_start_date_var]).dt.days\n",
    "    # if paused\n",
    "    # if  analysis start <= start date <= pause date  <= resume date <= analysis end <= interview date \n",
    "    res.loc[(res[paused_flag_in_aw_var]== 1) &\n",
    "            (pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (analysis_date_start <= res[rd_start_date_var]) &\n",
    "            (res[rd_start_date_var] <= res[rd_pause_date_var] ) &\n",
    "            (res[rd_resume_date_var] <= analysis_date_end) &\n",
    "            (analysis_date_end <= res[rd_interview_date_var]),\n",
    "            days_before_streatment_start_in_aw_var] = (res[rd_pause_date_var] - res[rd_start_date_var]).dt.days +\\\n",
    "                                                      (res[analysis_end_date_var] - res[rd_resume_date_var]).dt.days  \n",
    "    # if paused\n",
    "    # if  analysis start <= start date <= pause date  <= resume date <= analysis end, interview date not defined\n",
    "    res.loc[(res[paused_flag_in_aw_var]== 1) &\n",
    "            (pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 1) &\n",
    "            (analysis_date_start <= res[rd_start_date_var]) &\n",
    "            (res[rd_start_date_var] <= res[rd_pause_date_var] ) &\n",
    "            (res[rd_resume_date_var] <= analysis_date_end),\n",
    "            days_before_streatment_start_in_aw_var] = (res[rd_pause_date_var] - res[rd_start_date_var]).dt.days +\\\n",
    "                                                      (res[analysis_end_date_var] - res[rd_resume_date_var]).dt.days\n",
    "    # if paused\n",
    "    # if analysis start <= start date <= pause date  <= resume date <= interview date <= analysis end\n",
    "    res.loc[(res[paused_flag_in_aw_var]== 1) &\n",
    "            (pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (analysis_date_start <= res[rd_start_date_var]) &\n",
    "            (res[rd_start_date_var] <= res[rd_pause_date_var] ) &\n",
    "            (res[rd_resume_date_var] <=  res[rd_interview_date_var]) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_end),\n",
    "            days_before_streatment_start_in_aw_var] = (res[rd_pause_date_var] - res[rd_start_date_var]).dt.days +\\\n",
    "                                                      (res[rd_interview_date_var] - res[rd_resume_date_var]).dt.days  \n",
    "    # if paused\n",
    "    # if analysis start <= resume date <= start date  <= interview date <= analysis end\n",
    "    res.loc[(res[paused_flag_in_aw_var]== 1) &\n",
    "            (pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (analysis_date_start <= res[rd_resume_date_var]) &\n",
    "            (res[rd_resume_date_var] <= res[rd_start_date_var]) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_end),\n",
    "            days_before_streatment_start_in_aw_var] = (res[rd_interview_date_var] - res[rd_start_date_var]).dt.days\n",
    "    # if paused\n",
    "    # if analysis start <= resume date <= start date <= analysis end <= interview date\n",
    "    res.loc[(res[paused_flag_in_aw_var]== 1) &\n",
    "            (pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (analysis_date_start <= res[rd_resume_date_var]) &\n",
    "            (res[rd_resume_date_var] <= res[rd_start_date_var]) &\n",
    "            (res[rd_start_date_var] <= analysis_date_end)  &\n",
    "            (analysis_date_end <= res[rd_interview_date_var]),\n",
    "            days_before_streatment_start_in_aw_var] = (res[analysis_end_date_var] - res[rd_start_date_var]).dt.days\n",
    "    # if paused\n",
    "    # if analysis start <= resume date <= start date <= analysis end,  interview date not defined\n",
    "    res.loc[(res[paused_flag_in_aw_var]== 1) &\n",
    "            (pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 1) &\n",
    "            (analysis_date_start <= res[rd_resume_date_var]) &\n",
    "            (res[rd_resume_date_var] <= res[rd_start_date_var]) &\n",
    "            (res[rd_start_date_var] <= analysis_date_end),\n",
    "            days_before_streatment_start_in_aw_var] = (res[analysis_end_date_var] - res[rd_start_date_var]).dt.days\n",
    "    # if paused\n",
    "    # if analysis start <= start date <= intervew date date <= pause date <= analysis end\n",
    "    res.loc[(res[paused_flag_in_aw_var]== 1) &\n",
    "            (pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (analysis_date_start <= res[rd_start_date_var]) &\n",
    "            (res[rd_interview_date_var] <= res[rd_pause_date_var]) &\n",
    "            (res[rd_pause_date_var] <= analysis_date_end),\n",
    "            days_before_streatment_start_in_aw_var] = (res[rd_interview_date_var] - res[rd_start_date_var]).dt.days\n",
    "    # if paused\n",
    "    # if start date <= analysis start <=  intervew date date <= pause date <= analysis end\n",
    "    res.loc[(res[paused_flag_in_aw_var]== 1) &\n",
    "            (pd.isna(res[rd_start_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (res[rd_start_date_var] <= analysis_date_start) &\n",
    "            (res[rd_interview_date_var] <= res[rd_pause_date_var]) &\n",
    "            (res[rd_pause_date_var] <= analysis_date_end),\n",
    "            days_before_streatment_start_in_aw_var] = (res[rd_interview_date_var] - res[analysis_start_date_var]).dt.days\n",
    "    \n",
    "\n",
    "    # count days in treatment \n",
    "    res[days_in_treatment_in_aw_var] = 0\n",
    "    # if not cancelled and not paused in analysis window,\n",
    "    # if interview and end date defined and interview date >= analysis start and end date <= analysis end\n",
    "    res.loc[(res[cancellation_flag_in_aw_var]== 0) &\n",
    "            (res[paused_flag_in_aw_var]== 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (res[rd_interview_date_var] >= analysis_date_start) &\n",
    "            (pd.isna(res[rd_end_date_var]) == 0) & \n",
    "            (res[rd_end_date_var] <= analysis_date_end),\n",
    "            days_in_treatment_in_aw_var] = (res[rd_end_date_var] - res[rd_interview_date_var]).dt.days\n",
    "    # if not cancelled and not paused in analysis window,\n",
    "    # if interview and end date defined and interview date in analysis window, end date >= analysis end\n",
    "    res.loc[(res[cancellation_flag_in_aw_var]== 0) &\n",
    "            (res[paused_flag_in_aw_var]== 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (res[rd_interview_date_var] >= analysis_date_start) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_end) &\n",
    "            (pd.isna(res[rd_end_date_var]) == 0) & \n",
    "            (res[rd_end_date_var] >= analysis_date_end),\n",
    "            days_in_treatment_in_aw_var] = (res[analysis_end_date_var] - res[rd_interview_date_var]).dt.days\n",
    "    # if not cancelled and not paused in analysis window,\n",
    "    # if interview and end date defined and interview date <= analysis start and end date <= analysis end\n",
    "    res.loc[(res[cancellation_flag_in_aw_var]== 0) &\n",
    "            (res[paused_flag_in_aw_var]== 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_start) &\n",
    "            (pd.isna(res[rd_end_date_var]) == 0) & \n",
    "            (res[rd_end_date_var] <= analysis_date_end),\n",
    "            days_in_treatment_in_aw_var] = (res[rd_end_date_var] - res[analysis_start_date_var]).dt.days\n",
    "    # if not cancelled and not paused in analysis window,\n",
    "    # if interview and end date defined and interview date <= analysis start and end date >= analysis end\n",
    "    res.loc[(res[cancellation_flag_in_aw_var]== 0) &\n",
    "            (res[paused_flag_in_aw_var]== 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_start) &\n",
    "            (pd.isna(res[rd_end_date_var]) == 0) & \n",
    "            (res[rd_end_date_var] >= analysis_date_end),\n",
    "            days_in_treatment_in_aw_var] = (res[analysis_end_date_var] - res[analysis_start_date_var]).dt.days\n",
    "    # if not cancelled and not paused in analysis window, \n",
    "    # if interview date in analysis window, end date not defined\n",
    "    res.loc[(res[cancellation_flag_in_aw_var]== 0) &\n",
    "            (res[paused_flag_in_aw_var]== 0) &\n",
    "            (pd.isna(rd_interview_date_var) == 0) &\n",
    "            (res[rd_interview_date_var] >= analysis_date_start) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_end) &\n",
    "            (pd.isna(rd_end_date_var)== 1),\n",
    "           days_in_treatment_in_aw_var] = (res[analysis_end_date_var] - res[rd_interview_date_var]).dt.days\n",
    "    # if not cancelled and not paused in analysis window, \n",
    "    # if interview date <= analysis window, end date not defined\n",
    "    res.loc[(res[cancellation_flag_in_aw_var]== 0) &\n",
    "            (res[paused_flag_in_aw_var]== 0) &\n",
    "            (pd.isna(rd_interview_date_var) == 0) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_start) &\n",
    "            (pd.isna(rd_end_date_var)== 1),\n",
    "           days_in_treatment_in_aw_var] = (res[analysis_end_date_var] - res[analysis_start_date_var]).dt.days\n",
    "    # if cancelled and not paused in analysis window and cancel date not defined\n",
    "    res.loc[(res[cancellation_flag_in_aw_var] == 1) &\n",
    "            (res[paused_flag_in_aw_var] == 0) &\n",
    "            (pd.isna(res[rd_cancellation_date_var]) == 1),\n",
    "           days_in_treatment_in_aw_var] = 0\n",
    "    # if cancelled and not paused in analysis window and cancel date defined, interview date <= analysis start\n",
    "    res.loc[(res[cancellation_flag_in_aw_var] == 1) &\n",
    "            (res[paused_flag_in_aw_var]== 0) &\n",
    "            (pd.isna(res[rd_cancellation_date_var]) == 0) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_start),\n",
    "            days_in_treatment_in_aw_var] = (res[rd_cancellation_date_var] - res[analysis_start_date_var]).dt.days\n",
    "    # if cancelled and not paused in analysis window and cancel date defined, interview date in analysis window\n",
    "    res.loc[(res[cancellation_flag_in_aw_var] == 1) &\n",
    "            (res[paused_flag_in_aw_var] == 0) &\n",
    "            (pd.isna(res[rd_cancellation_date_var]) == 0) &\n",
    "            (res[rd_interview_date_var] >= analysis_date_start) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_end),\n",
    "            days_in_treatment_in_aw_var] = (res[rd_cancellation_date_var] - res[rd_interview_date_var]).dt.days\n",
    "    # if paused and not cancelled in analysis window, paused & resume date defined, \n",
    "    #    paused date <= analysis start, resumed date >= analysis end\n",
    "    res.loc[(res[cancellation_flag_in_aw_var]== 0) &\n",
    "            (res[paused_flag_in_aw_var] == 1) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (res[rd_pause_date_var] <= analysis_date_start) &\n",
    "            (res[rd_resume_date_var] >= analysis_date_end),\n",
    "            days_in_treatment_in_aw_var] = 0\n",
    "    # if paused and not cancelled in analysis window, paused date defined, resumed date not defined, \n",
    "    #    paused date <= analysis start\n",
    "    res.loc[(res[cancellation_flag_in_aw_var]== 0) & \n",
    "            (res[paused_flag_in_aw_var] == 1) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 1) &\n",
    "            (res[rd_pause_date_var] <= analysis_date_start),\n",
    "            days_in_treatment_in_aw_var] = 0\n",
    "    # if paused and not cancelled in analysis window, paused & resume date defined, \n",
    "    #    analysis start <= interview date <= paused date <= analysis end <= resumed date\n",
    "    res.loc[(res[cancellation_flag_in_aw_var]== 0) & \n",
    "            (res[paused_flag_in_aw_var] == 1) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (res[rd_interview_date_var] >= analysis_date_start) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_end) &\n",
    "            (res[rd_interview_date_var] <= res[rd_pause_date_var]) &\n",
    "            (res[rd_resume_date_var] >= analysis_date_end),\n",
    "            days_in_treatment_in_aw_var] = (res[rd_pause_date_var] - res[rd_interview_date_var]).dt.days\n",
    "    # if paused and not cancelled in analysis window, paused date defined, resume date not defined\n",
    "    #    analysis start <= interview date <= paused date <= analysis end\n",
    "    res.loc[(res[cancellation_flag_in_aw_var]== 0) & \n",
    "            (res[paused_flag_in_aw_var] == 1) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 1) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (res[rd_interview_date_var] >= analysis_date_start) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_end) &\n",
    "            (res[rd_interview_date_var] <= res[rd_pause_date_var]),\n",
    "            days_in_treatment_in_aw_var] = (res[rd_pause_date_var] - res[rd_interview_date_var]).dt.days\n",
    "    # if paused and not cancelled in analysis window, paused & resume date defined, \n",
    "    #    analysis start <= interview date <= paused date <= resumed date <= date end <= analysis end\n",
    "    res.loc[(res[cancellation_flag_in_aw_var]== 0) &\n",
    "            (res[paused_flag_in_aw_var] == 1) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_end_date_var]) == 0) &\n",
    "            (res[rd_interview_date_var] >= analysis_date_start) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_end) &\n",
    "            (res[rd_interview_date_var] <= res[rd_pause_date_var]) &\n",
    "            (res[rd_resume_date_var] <= res[rd_end_date_var])&\n",
    "            (res[rd_end_date_var] <= analysis_date_end),\n",
    "            days_in_treatment_in_aw_var] = (res[rd_pause_date_var] - res[rd_interview_date_var]).dt.days + \\\n",
    "                                           (res[rd_end_date_var] - res[rd_resume_date_var]).dt.days\n",
    "    # if paused and not cancelled in analysis window, paused & resume date defined, \n",
    "    #    analysis start <= interview date <= paused date <= resumed date <= analysis end <= date end \n",
    "    res.loc[(res[cancellation_flag_in_aw_var]== 0) & \n",
    "            (res[paused_flag_in_aw_var] == 1) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_end_date_var]) == 0) &\n",
    "            (res[rd_interview_date_var] >= analysis_date_start) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_end) &\n",
    "            (res[rd_interview_date_var] <= res[rd_pause_date_var]) &\n",
    "            (res[rd_resume_date_var] <= analysis_date_end) &\n",
    "            (res[rd_end_date_var] >= analysis_date_end),\n",
    "            days_in_treatment_in_aw_var] = (res[rd_pause_date_var] - res[rd_interview_date_var]).dt.days + \\\n",
    "                                           (res[analysis_end_date_var] - res[rd_resume_date_var]).dt.days\n",
    "    # if paused and not cancelled in analysis window, paused & resume date defined, \n",
    "    #    analysis start <= interview date <= paused date <= resumed date <= analysis end,  date end undefined\n",
    "    res.loc[(res[cancellation_flag_in_aw_var]== 0) &\n",
    "            (res[paused_flag_in_aw_var] == 1) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_end_date_var]) == 1) &\n",
    "            (res[rd_interview_date_var] >= analysis_date_start) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_end) &\n",
    "            (res[rd_interview_date_var] <= res[rd_pause_date_var]) &\n",
    "            (res[rd_resume_date_var] <= analysis_date_end),\n",
    "            days_in_treatment_in_aw_var] = (res[rd_pause_date_var] - res[rd_interview_date_var]).dt.days + \\\n",
    "                                           (res[analysis_end_date_var] - res[rd_resume_date_var]).dt.days\n",
    "    # if paused and not cancelled in analysis window, paused & resume date defined, \n",
    "    #    interview date <= analysis start <=  paused date <= analysis end <= resumed date\n",
    "    res.loc[(res[cancellation_flag_in_aw_var]== 0) & \n",
    "            (res[paused_flag_in_aw_var] == 1) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_start) &\n",
    "            (analysis_date_start <= res[rd_pause_date_var]) &\n",
    "            (res[rd_pause_date_var] <= analysis_date_end) &\n",
    "            (analysis_date_end <= res[rd_resume_date_var]),\n",
    "            days_in_treatment_in_aw_var] = (res[rd_pause_date_var] - res[analysis_start_date_var]).dt.days\n",
    "    # if paused and not cancelled in analysis window, paused date defined, resumed date not defined\n",
    "    #    interview date <= analysis start <=  paused date <= analysis end \n",
    "    res.loc[(res[cancellation_flag_in_aw_var]== 0) & \n",
    "            (res[paused_flag_in_aw_var] == 1) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 1) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_start) &\n",
    "            (analysis_date_start <= res[rd_pause_date_var]) &\n",
    "            (res[rd_pause_date_var] <= analysis_date_end),\n",
    "            days_in_treatment_in_aw_var] = (res[rd_pause_date_var] - res[analysis_start_date_var]).dt.days\n",
    "    # if paused and not cancelled in analysis window\n",
    "    #    interview date <= analysis start <=  paused date <= resumed date <= end date <= analysis end\n",
    "    res.loc[(res[cancellation_flag_in_aw_var]== 0) & \n",
    "            (res[paused_flag_in_aw_var] == 1) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_end_date_var]) == 0) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_start) &\n",
    "            (analysis_date_start <= res[rd_pause_date_var]) &\n",
    "            (res[rd_resume_date_var] <= res[rd_end_date_var]) &\n",
    "            (res[rd_end_date_var] <= analysis_date_end),\n",
    "            days_in_treatment_in_aw_var] = (res[rd_pause_date_var] - res[analysis_start_date_var]).dt.days + \\\n",
    "                                           (res[rd_end_date_var] - res[rd_resume_date_var]).dt.days\n",
    "    # if paused and not cancelled in analysis window\n",
    "    #    interview date <= analysis start <=  paused date <= resumed date <= analysis end <= end date \n",
    "    res.loc[(res[cancellation_flag_in_aw_var]== 0) & \n",
    "            (res[paused_flag_in_aw_var] == 1) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_end_date_var]) == 0) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_start) &\n",
    "            (analysis_date_start <= res[rd_pause_date_var]) &\n",
    "            (res[rd_resume_date_var] <= analysis_date_end) &\n",
    "            (analysis_date_end <= res[rd_end_date_var]),\n",
    "            days_in_treatment_in_aw_var] = (res[rd_pause_date_var] - res[analysis_start_date_var]).dt.days + \\\n",
    "                                           (res[analysis_end_date_var] - res[rd_resume_date_var]).dt.days\n",
    "    # if paused and not cancelled in analysis window\n",
    "    #    interview date <= analysis start <=  paused date <= resumed date <= analysis end, end date undefined\n",
    "    res.loc[(res[cancellation_flag_in_aw_var]== 0) & \n",
    "            (res[paused_flag_in_aw_var] == 1) &\n",
    "            (pd.isna(res[rd_pause_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_end_date_var]) == 1) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_start) &\n",
    "            (analysis_date_start <= res[rd_pause_date_var]) &\n",
    "            (res[rd_resume_date_var] <= analysis_date_end),\n",
    "            days_in_treatment_in_aw_var] = (res[rd_pause_date_var] - res[analysis_start_date_var]).dt.days + \\\n",
    "                                           (res[analysis_end_date_var] - res[rd_resume_date_var]).dt.days\n",
    "    # if paused and not cancelled in analysis window\n",
    "    #    analysis start <= resumed date <= interview date <= end date <= analysis end\n",
    "    res.loc[(res[cancellation_flag_in_aw_var]== 0) & \n",
    "            (res[paused_flag_in_aw_var] == 1) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_end_date_var]) == 0) &\n",
    "            (analysis_date_start <= res[rd_resume_date_var]) &\n",
    "            (res[rd_resume_date_var] <= res[rd_interview_date_var]) &\n",
    "            (res[rd_interview_date_var] <= res[rd_end_date_var]) &\n",
    "            (res[rd_end_date_var] <= analysis_date_end),\n",
    "            days_in_treatment_in_aw_var] = (res[rd_end_date_var] - res[rd_interview_date_var]).dt.days\n",
    "    # if paused and not cancelled in analysis window\n",
    "    #    analysis start <= resumed date <= interview date  <= analysis end <= end date\n",
    "    res.loc[(res[cancellation_flag_in_aw_var]== 0) & \n",
    "            (res[paused_flag_in_aw_var] == 1) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_end_date_var]) == 0) &\n",
    "            (analysis_date_start <= res[rd_resume_date_var]) &\n",
    "            (res[rd_resume_date_var] <= res[rd_interview_date_var]) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_end) &\n",
    "            (analysis_date_end <= res[rd_end_date_var]),\n",
    "            days_in_treatment_in_aw_var] = (res[analysis_end_date_var] - res[rd_interview_date_var]).dt.days\n",
    "    # if paused and not cancelled in analysis window\n",
    "    #    analysis start <= resumed date <= interview date  <= analysis end, end date not defined\n",
    "    res.loc[(res[cancellation_flag_in_aw_var]== 0) & \n",
    "            (res[paused_flag_in_aw_var] == 1) &\n",
    "            (pd.isna(res[rd_resume_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_interview_date_var]) == 0) &\n",
    "            (pd.isna(res[rd_end_date_var]) == 1) &\n",
    "            (analysis_date_start <= res[rd_resume_date_var]) &\n",
    "            (res[rd_resume_date_var] <= res[rd_interview_date_var]) &\n",
    "            (res[rd_interview_date_var] <= analysis_date_end),\n",
    "            days_in_treatment_in_aw_var] = (res[analysis_end_date_var] - res[rd_interview_date_var]).dt.days\n",
    "    # if paused and cancelled in analysis window\n",
    "                                                \n",
    "    \n",
    "    return res\n",
    "\n",
    "def impute_end_phase1_jp(df):\n",
    "    # impute end of phase 1 treatment in JobPath\n",
    "    # \tplease use rd_interview_date_var, which is the start of the phase 1 JobPath treatment\n",
    "\n",
    "    # if this episode ends with a cancellation, the imputed end date is cancellation date \n",
    "    # if this episode ends with a pause, and no resumption, then imputed end date = pause date \n",
    "    # if this episode includes a pause, and resumption date NE \"\", then imputed_end = resumption date +12 months - time from start to pause\n",
    "    # if no cancellation or pause flag, imputed_end = rd_interview_date_var plus 12 months \n",
    "    # if rd_interview_date_var = \"\" then imputed_end = Null\n",
    "    res = df.copy()\n",
    "    \n",
    "    # Set deafault value (this also handles NULL/NAT/NAN)\n",
    "    res[imputed_ph1_end_date_var] = res[rd_interview_date_var] + DateOffset(months=imputed_ph1_end_date_offset_months)\n",
    "    \n",
    "    # if cancellation date exists\n",
    "    res.loc[pd.isna(res[rd_cancellation_date_var]) == 0,\n",
    "            imputed_ph1_end_date_var] = res.loc[pd.isna(res[rd_cancellation_date_var]) == 0] [rd_cancellation_date_var]\n",
    "    \n",
    "    # if pause date exists\n",
    "    res.loc[pd.isna(res[rd_pause_date_var]) == 0,\n",
    "            imputed_ph1_end_date_var] = res.loc[pd.isna(res[rd_pause_date_var]) == 0] [rd_pause_date_var]\n",
    "    \n",
    "    # if resume date exists\n",
    "    res.loc[pd.isna(res[rd_resume_date_var]) == 0,\n",
    "            imputed_ph1_end_date_var] = res.loc[pd.isna(res[rd_resume_date_var]) == 0] [rd_resume_date_var] +\\\n",
    "                                        DateOffset(months=imputed_ph1_end_date_offset_months) - \\\n",
    "                                        (res.loc[pd.isna(res[rd_resume_date_var]) == 0][rd_pause_date_var] - \\\n",
    "                                         res.loc[pd.isna(res[rd_resume_date_var]) == 0][rd_interview_date_var])\n",
    "    \n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "def summary_post_processing(df):\n",
    "    res = df.copy()\n",
    "    \n",
    "    res[jobpath_category_in_aw_var] = ''\n",
    "    \n",
    "    res.loc[res[completed_ph1_jp_before_aw_var] == 1,\n",
    "            jobpath_category_in_aw_var] = 'completed jp before aw'\n",
    "    \n",
    "    res.loc[res[started_jp_after_aw_var] == 1,\n",
    "            jobpath_category_in_aw_var] = 'started jp after aw'\n",
    "    \n",
    "    res.loc[(res[started_jp_after_aw_var] == 0) &\n",
    "            (res[completed_ph1_jp_before_aw_var] == 0),\n",
    "            jobpath_category_in_aw_var] = 'no jp before or after aw'\n",
    "    \n",
    "    res.loc[res[jp_started_before_aw_completed_ph1_in_aw_var] == 1,\n",
    "            jobpath_category_in_aw_var] = 'started before aw completed during aw'\n",
    "    \n",
    "    res.loc[res[jp_started_in_aw_completed_ph1_after_aw_var] == 1,\n",
    "            jobpath_category_in_aw_var] = 'started before aw finished after aw'\n",
    "    \n",
    "    res.loc[res[jp_ph1_completed_in_aw_firstQ_year2_var] == 1,\n",
    "            jobpath_category_in_aw_var] = 'Q1 Y2 complete'\n",
    "    \n",
    "    res.loc[res[jp_ph1_completed_in_aw_secondQ_year2_var] == 1,\n",
    "            jobpath_category_in_aw_var] = 'Q2 Y2 complete'\n",
    "    \n",
    "    res.loc[res[jp_ph1_completed_in_aw_thirdQ_year2_var] == 1,\n",
    "            jobpath_category_in_aw_var] = 'Q3 Y2 complete'\n",
    "    \n",
    "    res.loc[res[jp_ph1_completed_in_aw_fourthQ_year2_var] == 1,\n",
    "            jobpath_category_in_aw_var] = 'Q4 Y2 complete'\n",
    "    \n",
    "    res.loc[res[jp_cancelled_before_start_in_aw_var] == 1,\n",
    "            jobpath_category_in_aw_var] = 'cancelled before start in aw'\n",
    "    \n",
    "    res.loc[res[jp_cancelled_in_aw_start_before_aw_var] == 1,\n",
    "            jobpath_category_in_aw_var] = 'cancelled in aw started before aw'\n",
    "    \n",
    "    res.loc[res[jp_cancelled_in_aw_start_in_aw_var] == 1,\n",
    "            jobpath_category_in_aw_var] = 'cancelled in aw started during aw'\n",
    "    \n",
    "    res.loc[res[jp_cancelled_afer_aw_start_in_aw_var] == 1,\n",
    "            jobpath_category_in_aw_var] = 'cancelled post aw'\n",
    "    return res\n",
    "\n",
    "start_time = time.time()\n",
    "print ('Reading Referral Data and ETL')\n",
    "referral_data = pd.DataFrame()\n",
    "for filename in referral_data_csvfilenames:\n",
    "        referral_data = referral_data.append(pd.read_csv(filename, low_memory=False), ignore_index= True)\n",
    "\n",
    "referral_data.rename(columns={rd_uid_var: uid_var}, inplace=True)\n",
    "for elem in rd_date_fields:\n",
    "    referral_data[elem] = pd.to_datetime(referral_data[elem], errors ='coerce', format= rd_date_format)\n",
    "\n",
    "print ('Removing Duplicates in Referral Data')\n",
    "referral_data = remove_dups_in_referral_data(referral_data)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print ('Elapsed time: '+ time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "\n",
    "start_time = time.time()\n",
    "if (len(clusters_sql_tables) != len(analysis_date_end_strings)) | \\\n",
    "   (len(clusters_sql_tables) != len(analysis_date_start_strings)) | \\\n",
    "   (len(clusters_sql_tables) != len(flat_jld_sql_tables)):\n",
    "    print ('Mismatched input parameters!\\nPlease Check: clusters_sql_tables, flat_jld_sql_tables, analysis_date_end_strings, analysis_date_start_strings')\n",
    "else:\n",
    "    for i in range(len(clusters_sql_tables)):\n",
    "        print('Processing table: %s' %(clusters_sql_tables[i]))\n",
    "        \n",
    "        analysis_date_start= dt.datetime.strptime(analysis_date_start_strings[i], analysis_dates_string_format)\n",
    "        analysis_date_end = dt.datetime.strptime(analysis_date_end_strings[i], analysis_dates_string_format)\n",
    "        print('\\tAnalysis Start: %s' %(analysis_date_start.strftime('%d/%m/%Y')))\n",
    "        print('\\tAnalysis End: %s' %(analysis_date_end.strftime('%d/%m/%Y')))\n",
    "        \n",
    "        print ('\\tCreating JP Summary')\n",
    "        summary = impute_end_phase1_jp(referral_data)\n",
    "        summary = summarise_data_in_aw(summary,analysis_date_start, analysis_date_end)\n",
    "        summary = summarise_data_before_aw(summary, analysis_date_start)\n",
    "        summary = summarise_data_after_aw(summary, analysis_date_end)     \n",
    "        summary = summary_post_processing(summary)\n",
    "        \n",
    "        # format strings\n",
    "        rd_string_fields.append(jobpath_category_in_aw_var)\n",
    "        for elem in rd_string_fields:\n",
    "            summary[elem] = summary[elem].astype(str)\n",
    "            summary[elem] = summary[elem].apply(lambda x: re.sub('\\W+',' ', x ))\n",
    "            summary[elem] = summary[elem].apply(lambda x: x.encode('utf-8').strip())\n",
    "        \n",
    "        print ('\\tRead Cluster Data: %s' %(clusters_sql_tables[i]))\n",
    "        clusters = read_data_from_sql(clusters_sql_tables[i])\n",
    "\n",
    "        print ('\\tLeft Join Cluster Data and Summary')\n",
    "        summary = pd.merge(clusters, summary, on=uid_var, how='left')\n",
    "        \n",
    "        print('\\tRead Flat JLD Data: %s' %(flat_jld_sql_tables[i]))\n",
    "        fjld_data = read_data_from_sql(flat_jld_sql_tables[i])\n",
    "        fjld_data = fjld_data[flat_jld_selected_variables]\n",
    "        \n",
    "        print ('\\tLeft Join Summary Data and Flat JLD Data')\n",
    "        summary = pd.merge(summary,fjld_data, on=uid_var, how='left')\n",
    "        \n",
    "        suffix = '_P0'\n",
    "        summary[jp_prefix_elegible_var+suffix] = 0\n",
    "        summary.loc[summary[jp_eligible_target_var] >= jp_eligible_target_var_min_val, \n",
    "                    jp_prefix_elegible_var+suffix] = 1\n",
    "        \n",
    "        for p in range(number_of_periods):\n",
    "            print('\\t\\tProcessing period: %d' %(p+1))\n",
    "            \n",
    "            period_start = analysis_date_start +DateOffset(months=periods_lenght_month*p)\n",
    "            period_end = analysis_date_start +DateOffset(months=periods_lenght_month*(p+1))\n",
    "            print('\\t\\tPeriod Start: %s' %(period_start.strftime('%d/%m/%Y')))\n",
    "            print('\\t\\tPeriod End: %s' %(period_end.strftime('%d/%m/%Y')))\n",
    "            \n",
    "            suffix = '_P'+str(p+1)\n",
    "            summary[jp_prefix_elegible_var+suffix] = 0\n",
    "            summary.loc[ summary[jp_eligible_target_var] + (p+1)*periods_lenght_month >= jp_eligible_target_var_min_val, \n",
    "                        jp_prefix_elegible_var+suffix] = 1\n",
    "            \n",
    "            summary[jp_prefx_started_var+suffix] = 0\n",
    "            summary.loc[(pd.isna(summary[jp_prefx_started_target_var]) ==0) &\n",
    "                        (summary[jp_prefx_started_target_var] >= period_start) &\n",
    "                        (summary[jp_prefx_started_target_var] < period_end),\n",
    "                        jp_prefx_started_var+suffix ] = 1\n",
    "            \n",
    "            print('\\t\\tExtracting info from JLD: %s' %(jld_sql_table))\n",
    "            summary = check_jld(summary, period_start, period_end, suffix)\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "            print ('\\t\\tElapsed time: '+ time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "        \n",
    "        if export_to_csv:\n",
    "            print('\\tExport to CSV')\n",
    "            summary.to_csv(csv_path+clusters_sql_tables[i]+out_suffix+'.csv', index=False)\n",
    "        if upload_to_sql:\n",
    "            print('\\tUpload to SQL')\n",
    "            upload_df_to_sql(summary, clusters_sql_tables[i]+out_suffix)\n",
    "        \n",
    "\n",
    "print ('ALL DONE')\n",
    "elapsed_time = time.time() - start_time\n",
    "print ('Elapsed time: '+ time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cluster', 'ppsn', 'Amended Referral Status', 'Cancellationsubcategory',\n",
       "       'Claim Office Code', 'Claim Office Name', 'Date of Cancellation',\n",
       "       'Date of Interview', 'Date_paused', 'Dateresumed',\n",
       "       ...\n",
       "       'StartDate_P4', 'ada_code_rank_P4', 'family_flag_rank_P4',\n",
       "       'hist_lls_P4', 'hist_lr_P4', 'lr_flag_P4', 'marital_status_rank_P4',\n",
       "       'occupation_rank_P4', 'status_simple_P4', 'status_P4'],\n",
       "      dtype='object', length=115)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
