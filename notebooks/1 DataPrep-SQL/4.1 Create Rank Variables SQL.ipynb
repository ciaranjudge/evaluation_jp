{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, event\n",
    "import pyodbc\n",
    "import urllib.parse\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs & Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL database\n",
    "server = 'CSKMA0400\\RDB_Data'\n",
    "db = 'JLDJobPath'\n",
    "odbc_connection_string = 'DRIVER={SQL Server Native Client 11.0};SERVER='+server+';DATABASE='+db+';Trusted_Connection=yes'\n",
    "#input table\n",
    "sql_table = \"linkedclaims_casuals_2018m04\"\n",
    "#output table\n",
    "sql_table_out = \"linkedclaims_casuals_2018m04_v2\"\n",
    "\n",
    "#input data dictionary file\n",
    "ddictionaryfilename = \"D:/Data/linkedclaims_casuals_2018m04_variables_types.csv\"\n",
    "#output data dictionary file\n",
    "ddictionaryfilename_out = \"D:/Data/linkedclaims_casuals_2018m04_v2_variables_types.csv\"\n",
    "\n",
    "## Define varibales for joining in SQL\n",
    "datadictionary = pd.read_csv(ddictionaryfilename)\n",
    "variable_uid = (datadictionary[datadictionary.UID == 1].Variable).tolist()[0]\n",
    "variable_event_start = (datadictionary[datadictionary.EventStart == 1].Variable).tolist()[0]\n",
    "variable_event_end = (datadictionary[datadictionary.EventEnd == 1].Variable).tolist()[0]\n",
    "variable_event_type = 'hist_lr'\n",
    "\n",
    "# Variable to create from, new variable name and type\n",
    "variable = ['occupation','LM_code','ada_code','family_flag', 'marital_status']\n",
    "new_variable = ['occupation_rank','LM_code_rank', 'ada_code_rank','family_flag_rank', 'marital_status_rank']\n",
    "new_variable_type = ['Num','Num','Num','Num','Num']\n",
    "ranking_rule = [\n",
    "                    [\n",
    "                        {10:[\"ManagersAndAdministrators\"]},\n",
    "                        {9:[\"ProfessionalOccupations\"]},\n",
    "                        {8:[\"AssociateProfessionalAndTechnicalOccupations\"]},\n",
    "                        {7:[\"ClericalAndSecretarialOccupations\"]},\n",
    "                        {6:[\"CraftAndRelatedOccupations\"]},\n",
    "                        {5:[\"PersonalAndProtectiveServiceOccupations\"]},\n",
    "                        {4:[\"SalesAndCustomerServiceOccupations\"]},\n",
    "                        {3:[\"PlantAndMachineOperatives\"]},\n",
    "                        {2:[\"OtherOccupations\"]},\n",
    "                        {1:[\"UnknownOrNotStatedOccupationOrThoseWhoNeverWorked\"]},\n",
    "                        {np.nan:[\"NULL\"]}\n",
    "                    ],\n",
    "                    [\n",
    "                        {1:['Employment']}, \n",
    "                        {3:['Part-Time']},\n",
    "                        {4:['Activation_and_Emp_Subs']}, \n",
    "                        {4:['Education_and_Training']}, \n",
    "                        {4:['Income_Subsidies']},\n",
    "                        {5:['One_Parent_Family']},\n",
    "                        {6:['Credits']}, \n",
    "                        {6:['Unemp_Benefit_Assistance']},\n",
    "                        {np.nan:[\"NULL\"]}\n",
    "                    ],\n",
    "                    [\n",
    "                        {11:['SpouseEarnings_bigger_than_Euro_400']}, \n",
    "                        {10:['SpouseEarnings_between_Euro_310_400']},\n",
    "                        {9:['SpouseEarnings_bigger_than_Euro_310']},\n",
    "                        {8:['SpouseEarnings_between_Euro_100_310']},\n",
    "                        {7:['SpouseEarnings_less_than_Euro_100']},\n",
    "                        {6:['SpouseHasEarningsPreviously_E_P_T']},\n",
    "                        {5:['SpouseNoIncome']},\n",
    "                        {4:['SpouseOnSocialWelfare']},\n",
    "                        {3:['SpouseUnknown']},\n",
    "                        {2:['NoSpouse_SingleSeparatedDivorcedWidowed']},\n",
    "                        {1:['NoDetails']},\n",
    "                        {np.nan:[\"NULL\"]}\n",
    "                    ],\n",
    "                    [\n",
    "                        {4:['ADA and CDAs']},\n",
    "                        {3:['ADA only']},\n",
    "                        {2:['CDAs only']},\n",
    "                        {1:['No ADA, no CDAs']}, \n",
    "                        {np.nan:[\"NULL\"]}\n",
    "                    ],\n",
    "                    [\n",
    "                        {3:['Widowed']},\n",
    "                        {2:['Married']},\n",
    "                        {1:['Single']},\n",
    "                        {np.nan:[\"NULL\"]}\n",
    "                    ]\n",
    "    \n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data from : linkedclaims_casuals_2018m04\n",
      "Creating new variable occupation_rank from occupation\n",
      "Creating Renamig Dictionaries\n",
      "Renamig\n",
      "\n",
      "Creating new variable LM_code_rank from LM_code\n",
      "Creating Renamig Dictionaries\n",
      "Renamig\n",
      "\n",
      "Creating new variable ada_code_rank from ada_code\n",
      "Creating Renamig Dictionaries\n",
      "Renamig\n",
      "\n",
      "Creating new variable family_flag_rank from family_flag\n",
      "Creating Renamig Dictionaries\n",
      "Renamig\n",
      "\n",
      "Creating new variable marital_status_rank from marital_status\n",
      "Creating Renamig Dictionaries\n",
      "Renamig\n",
      "\n",
      "\n",
      "Uploading to Temp Table SQL: linkedclaims_casuals_2018m04_v2_temp\n",
      "\n",
      "Joining Tables into linkedclaims_casuals_2018m04_v2\n",
      "\n",
      "Drop Temp Table\n",
      "SQL Process time: 00:38:39\n",
      "\n",
      "Update Data Dictionary File: D:/Data/linkedclaims_casuals_2018m04_v2_variables_types.csv\n",
      "\n",
      "ALL DONE\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "print('Loading Data from : %s' %(sql_table))\n",
    "## Connect to SQL\n",
    "params = urllib.parse.quote_plus(odbc_connection_string)\n",
    "engine = create_engine('mssql+pyodbc:///?odbc_connect=%s' % params)\n",
    "conn = engine.connect().connection\n",
    "\n",
    "@event.listens_for(engine, 'before_cursor_execute')\n",
    "def receive_before_cursor_execute(conn, cursor, statement, params, context, executemany):\n",
    "    if executemany:\n",
    "        cursor.fast_executemany = True\n",
    "\n",
    "sql_query_string = \"SELECT \"+ (',').join(variable) + \\\n",
    "                    \",\" + variable_uid + \",\" + variable_event_start + \\\n",
    "                    \",\" + variable_event_end + \",\" + variable_event_type + \" FROM \"+ sql_table\n",
    "df = pd.read_sql_query(sql_query_string, engine)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "for i in range(len(variable)):\n",
    "    var = variable[i]\n",
    "    new_var = new_variable[i]\n",
    "    new_var_type = new_variable_type[i]\n",
    "    rule = ranking_rule[i]\n",
    "\n",
    "    print('Creating new variable %s from %s' %(new_var, var))\n",
    "    df[new_var] = df[var]\n",
    "\n",
    "    print('Creating Renamig Dictionaries')\n",
    "    renaming_dict = []\n",
    "    old_values = df[new_var].unique().tolist()\n",
    "    for ov in old_values:\n",
    "        for rr in rule:\n",
    "            key = list(rr.keys())[0]\n",
    "            val = list(rr.values())[0]\n",
    "            if ov in val:\n",
    "                mydict = {new_var:{ov: key}}\n",
    "                renaming_dict.append(mydict)\n",
    "    \n",
    "    ## Replace values\n",
    "    print('Renamig\\n')\n",
    "    for elem in renaming_dict:\n",
    "#         print (elem)\n",
    "        df.replace(to_replace=elem, inplace=True)\n",
    "\n",
    "# Load into SQL\n",
    "same_table_in_out = False\n",
    "if sql_table == sql_table_out:\n",
    "    same_table_in_out = True\n",
    "    sql_table_out = '_'+sql_table_out\n",
    "sql_table_temp = sql_table_out+\"_temp\"\n",
    "\n",
    "## Connect to SQL\n",
    "mytime = time.time()\n",
    "params = urllib.parse.quote_plus(odbc_connection_string)\n",
    "engine = create_engine('mssql+pyodbc:///?odbc_connect=%s' % params)\n",
    "conn = engine.connect().connection\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# SpeedUp For fast execution of mutiple row \n",
    "@event.listens_for(engine, 'before_cursor_execute')\n",
    "def receive_before_cursor_execute(conn, cursor, statement, params, context, executemany):\n",
    "    if executemany:\n",
    "        cursor.fast_executemany = True\n",
    "\n",
    "## Drop table if exists\n",
    "sql_string_drop = \"IF OBJECT_ID('\"+ sql_table_temp + \"', 'U') IS NOT NULL\" +'\\n'+ \"DROP TABLE \" + sql_table_temp\n",
    "cursor.execute(sql_string_drop)\n",
    "conn.commit()\n",
    "\n",
    "## upload data\n",
    "print('\\nUploading to Temp Table SQL: %s' %(sql_table_temp))\n",
    "df.drop(columns=variable, inplace=True)\n",
    "df.to_sql(sql_table_temp, engine, if_exists='append', index=False)\n",
    "\n",
    "## Left Join\n",
    "## Drop table if exists\n",
    "sql_string_drop = \"IF OBJECT_ID('\"+ sql_table_out + \"', 'U') IS NOT NULL\" +'\\n'+ \"DROP TABLE \" + sql_table_out\n",
    "cursor.execute(sql_string_drop)\n",
    "conn.commit()\n",
    "\n",
    "print('\\nJoining Tables into %s' %(sql_table_out))\n",
    "sql_left_join = 'SELECT A.*, B.* INTO '+ sql_table_out + '\\n' +\\\n",
    "                ' FROM ' + sql_table + ' AS A LEFT JOIN ' + \\\n",
    "                '(SELECT '+ (',').join(new_variable) + \\\n",
    "                ',' + variable_uid + ' AS id,' + variable_event_start + ' AS s,' + variable_event_end +\\\n",
    "                ' AS e,' + variable_event_type + ' AS t FROM ' + sql_table_temp +') AS B \\n' + \\\n",
    "                ' ON A.'+ variable_uid +' = '+'B.id AND ' +\\\n",
    "                ' A.'+ variable_event_start +' = '+'B.s AND ' +\\\n",
    "                ' A.'+ variable_event_end +' = '+'B.e AND ' +\\\n",
    "                ' A.'+ variable_event_type +' = '+'B.t'\n",
    "\n",
    "cursor.execute(sql_left_join)\n",
    "conn.commit()\n",
    "\n",
    "# Drop id, s, e from joined table\n",
    "sql_drop_column = \"ALTER TABLE \" + sql_table_out + \" DROP COLUMN \" + \"id, s, e, t\";\n",
    "cursor.execute(sql_drop_column)\n",
    "conn.commit()\n",
    "\n",
    "## Drop temp table if exists\n",
    "print('\\nDrop Temp Table')\n",
    "sql_string_drop = \"IF OBJECT_ID('\"+ sql_table_temp + \"', 'U') IS NOT NULL\" +'\\n'+ \"DROP TABLE \" + sql_table_temp\n",
    "cursor.execute(sql_string_drop)\n",
    "conn.commit()\n",
    "\n",
    "## rename out if required\n",
    "if same_table_in_out == True:\n",
    "    print ('Copying into output table: %s' %(sql_table))\n",
    "    sql_string_drop = \"IF OBJECT_ID('\"+ sql_table + \"', 'U') IS NOT NULL\" +'\\n'+ \"DROP TABLE \" + sql_table\n",
    "    cursor.execute(sql_string_drop)\n",
    "    conn.commit()\n",
    "\n",
    "    sql_copy = 'SELECT * INTO ' + sql_table + ' FROM ' + sql_table_out\n",
    "    cursor.execute(sql_copy)\n",
    "    conn.commit()\n",
    "    \n",
    "    sql_string_drop = \"IF OBJECT_ID('\"+ sql_table_out + \"', 'U') IS NOT NULL\" +'\\n'+ \"DROP TABLE \" + sql_table_out\n",
    "    cursor.execute(sql_string_drop)\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "#Close SQL Connection\n",
    "conn.close()\n",
    "\n",
    "elapsed_time = time.time() - mytime\n",
    "print ('SQL Process time: '+ time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "\n",
    "# UPDATE DATADICTIONARY FILE WITH NEW COL NAME/TYPE/SELECTED\n",
    "\n",
    "print('\\nUpdate Data Dictionary File: %s' %(ddictionaryfilename_out))\n",
    "for i in range(len(new_variable)):\n",
    "    new_var = new_variable[i]\n",
    "    new_var_type = new_variable_type[i]\n",
    "    datadictionary = datadictionary.append({'Variable':new_var,'Type':new_var_type,'TotalSummary':1,'EpisodeSummary':1}, ignore_index=True)\n",
    "\n",
    "datadictionary.to_csv(ddictionaryfilename_out, index=False)\n",
    "\n",
    "print ('\\nALL DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
