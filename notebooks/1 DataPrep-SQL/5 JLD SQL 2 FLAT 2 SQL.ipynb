{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, event\n",
    "import pyodbc\n",
    "import urllib.parse\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs & Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL database\n",
    "server = 'CSKMA0400\\RDB_Data'\n",
    "db = 'JLDJobPath'\n",
    "odbc_connection_string = 'DRIVER={SQL Server Native Client 11.0};SERVER='+server+';DATABASE='+db+';Trusted_Connection=yes'\n",
    "\n",
    "# Set query date to roll-up to and number of episodes to include\n",
    "query_date = '20160401'\n",
    "n_episodes = 5\n",
    "n_years = 0\n",
    "\n",
    "#input table\n",
    "jld_sql_table = \"linkedclaims_casuals_2018m04_v2\"\n",
    "#output table\n",
    "flat_jld_sql_table = jld_sql_table+\"_flat_\" + query_date\n",
    "\n",
    "# Data dictionary below MUST include the variables and selection for jld_sql_table above!\n",
    "ddictionaryfilename = \"D:/Data/linkedclaims_casuals_2018m04_v2_variables_types.csv\"\n",
    "\n",
    "# Set the below to True to extract total duration across episodes of levels of nominal variables\n",
    "# Note the process is slow \n",
    "calculate_total_duration_days_of_levels = True\n",
    "\n",
    "# set variable and its value to exlude episodes in the query\n",
    "# variable_event_type = 'hist_lr'\n",
    "# variable_event_type_value = 'EMPL'\n",
    "# variable_event_type_condition = '!='\n",
    "variable_event_type = 'lr_flag'\n",
    "variable_event_type_value = '1'\n",
    "variable_event_type_condition = '='"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select PPSN, Flat/Transpose & SQL Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def batch(iterable, n = 1):\n",
    "    current_batch = []\n",
    "    for item in iterable:\n",
    "        current_batch.append(item)\n",
    "        if len(current_batch) == n:\n",
    "            yield current_batch\n",
    "            current_batch = []\n",
    "    if current_batch:\n",
    "        yield current_batch\n",
    "\n",
    "def sanitize_varchar(varchar):\n",
    "    sanitized = varchar.replace(' ','_')\n",
    "    sanitized = sanitized.replace(',','_')\n",
    "    sanitized = sanitized.replace('.','_')\n",
    "    sanitized = sanitized.replace('-','_')\n",
    "    sanitized = sanitized.replace('/','_')\n",
    "    return sanitized\n",
    "        \n",
    "def values_from_list_to_dict (values, base_key, max_n_values):\n",
    "    mydict = {}\n",
    "    for i in range(max_n_values):\n",
    "        key_value = base_key + '_' + str(i)\n",
    "        try:\n",
    "            mydict[key_value] = values[i]\n",
    "        except:\n",
    "            mydict[key_value] = None\n",
    "    return mydict\n",
    "\n",
    "def values_from_list_to_dict_as_string (values, base_key, max_n_values):\n",
    "    mydict = {}\n",
    "    for i in range(max_n_values):\n",
    "        key_value = base_key + '_' + str(i)\n",
    "        try:\n",
    "            mydict[key_value] = sanitize_varchar(str(values[i]))\n",
    "        except:\n",
    "            mydict[key_value] = 'NULL'\n",
    "    return mydict\n",
    "\n",
    "def unique_value_from_nparray(values):\n",
    "    values = pd.unique(values)\n",
    "    values = values[pd.notnull(values)]\n",
    "    value = np.nan\n",
    "    if len(values) > 0:\n",
    "        value = values[0]\n",
    "    return value\n",
    "\n",
    "def transpose_jld(data, dictionary, \n",
    "                  total_summary_episodes=0, \n",
    "                  total_number_of_years=0, \n",
    "                  max_date = None,\n",
    "                  calculate_total_duration_days_of_levels = False):\n",
    "    \n",
    "    variable_uid = (datadictionary[datadictionary.UID == 1].Variable).tolist()[0]\n",
    "    variable_event_start = (datadictionary[datadictionary.EventStart == 1].Variable).tolist()[0]\n",
    "    variable_event_end = (datadictionary[datadictionary.EventEnd == 1].Variable).tolist()[0]\n",
    "    \n",
    "    variable_date_of_birth = None\n",
    "    tmp = (datadictionary[datadictionary.DOB == 1].Variable).tolist()\n",
    "    if len (tmp) > 0:\n",
    "        variable_date_of_birth = tmp[0]\n",
    "    \n",
    "    # Get the list of variables that are Pinfo\n",
    "    pii_variables = (datadictionary[datadictionary.Pinfo == 1].Variable).tolist()\n",
    "    \n",
    "    # Get the list of variables that are total_summary\n",
    "    total_summary_variables = (datadictionary[datadictionary.TotalSummary == 1])\n",
    "    total_summary_variables_num = (total_summary_variables[total_summary_variables.Type == 'Num'])\n",
    "    total_summary_variables_char = (total_summary_variables[total_summary_variables.Type == 'Char'])\n",
    "    total_summary_variables = total_summary_variables.Variable.tolist()\n",
    "    total_summary_variables_num = total_summary_variables_num.Variable.tolist()\n",
    "    total_summary_variables_char = total_summary_variables_char.Variable.tolist()\n",
    "\n",
    "    # Get the list of variables that are episode_summary\n",
    "    episode_summary_variables = (datadictionary[datadictionary.EpisodeSummary == 1])\n",
    "    episode_summary_variables_char = (episode_summary_variables[episode_summary_variables.Type == 'Char'])\n",
    "    episode_summary_variables = episode_summary_variables.Variable.tolist()\n",
    "    episode_summary_variables_char = episode_summary_variables_char.Variable.tolist()\n",
    "    \n",
    "    # remove spurious rows and fix NaT in dates \n",
    "    # NaT are due to previous CVS 2 SQL step when processing original date > 2262-04-11 or original date < 1677-09-21\n",
    "    # see: http://pandas.pydata.org/pandas-docs/stable/timeseries.html#timeseries-timestamp-limits\n",
    "    if max_date is not None:\n",
    "        data.drop(data[data[variable_event_start] >= max_date].index, inplace=True)\n",
    "        data.loc[data[variable_event_end] > max_date, variable_event_end] = max_date\n",
    "        data[variable_event_end].fillna(max_date, inplace=True)\n",
    "    \n",
    "    # Calculate year value for per-year summaries\n",
    "    max_year = np.max(data[variable_event_end])\n",
    "    year_range = [x for x in range(max_year.year, max_year.year-total_number_of_years,-1)]\n",
    "    \n",
    "    ret =[]\n",
    "    grp_data = data.groupby(variable_uid)\n",
    "    for uid, group in grp_data:\n",
    "        mygroup = group.sort_values([variable_event_end, 'lr_flag', 'hist_lr', variable_event_start], \n",
    "                                    ascending = [False,False,False,False])\n",
    "        mydict = {}\n",
    "#         print (mygroup[['ppsn','StartDate','EndDate','hist_lr','lr_flag']])\n",
    "        \n",
    "        # save uid value if uid is not indicated in pii variables\n",
    "        if len (pii_variables) == 0 or variable_uid not in pii_variables:\n",
    "            myname = sanitize_varchar(variable_uid)\n",
    "            mydict[myname] = uid\n",
    "        \n",
    "        # save total number of episodes\n",
    "        mydict['total_n_episodes'] = float(len(mygroup))\n",
    "        \n",
    "        # save total duration of all episodes\n",
    "        starts = np.array(mygroup[variable_event_start])\n",
    "        ends = np.array(mygroup[variable_event_end])\n",
    "        diff = (ends.astype('datetime64[us]') - starts.astype('datetime64[us]')).astype('timedelta64[D]')\n",
    "        total_duration_days = np.nansum (diff)\n",
    "        mydict ['total_duration_days'] = total_duration_days.astype(int)\n",
    "        \n",
    "        # save all pii variables exept DOB\n",
    "        for elem in pii_variables:\n",
    "                values = np.array(mygroup[elem])\n",
    "                value = unique_value_from_nparray(values)\n",
    "                myname = sanitize_varchar(elem)\n",
    "                mydict[myname] = value\n",
    "\n",
    "        # Calculate Age if DOB availabe and max_date provided\n",
    "        mydict['age'] = np.nan\n",
    "        if variable_date_of_birth is not None : \n",
    "            elem = variable_date_of_birth\n",
    "            values = np.array(mygroup[elem])\n",
    "            value = unique_value_from_nparray(values)\n",
    "            myname = sanitize_varchar(elem)\n",
    "            mydict[myname] = value\n",
    "            if max_date is not None and pd.isnull(value) == False:\n",
    "                max_date_np = np.array(max_date)\n",
    "                age = (max_date_np.astype('datetime64[us]') - value.astype('datetime64[us]')).astype('timedelta64[Y]')\n",
    "                mydict['age'] = age.astype(int)\n",
    "\n",
    "        \n",
    "        # Calculate sum, mean, min and max of all numeric variables in total_summary_variables\n",
    "        for elem in total_summary_variables_num:\n",
    "            values = np.array(mygroup[elem])\n",
    "            values = values[~pd.isnull(values)]\n",
    "            myname = sanitize_varchar(str(elem))\n",
    "            if len(values) > 0:\n",
    "                values = values.astype(float)\n",
    "                mydict['total_sum_'+myname] = np.sum(values)\n",
    "                mydict['total_mean_'+myname] = np.mean(values)\n",
    "                mydict['total_max_'+myname] = np.max(values)\n",
    "                mydict['total_min_'+myname] = np.min(values)\n",
    "            else:\n",
    "                mydict['total_sum_'+myname] = np.nan\n",
    "                mydict['total_mean_'+myname] = np.nan\n",
    "                mydict['total_max_'+myname] = np.nan\n",
    "                mydict['total_min_'+myname] = np.nan\n",
    "                \n",
    "        # Calculate count and duration in days of levels of all character (aka nominal) variables in total_summary_variables\n",
    "        for elem in total_summary_variables_char:\n",
    "            res = mygroup[elem].value_counts()\n",
    "            for value in res.index:\n",
    "                if value != 'NULL':\n",
    "                    myname = sanitize_varchar(str(elem))\n",
    "                    myvalue = sanitize_varchar(str(value))\n",
    "                    mydict ['total_n_'+myname+'_'+myvalue] = res.loc[value]\n",
    "                    \n",
    "                    # this is slow\n",
    "                    if calculate_total_duration_days_of_levels == True:\n",
    "                        mydf = mygroup[mygroup[elem] == value]\n",
    "                        starts = np.array(mydf[variable_event_start])\n",
    "                        ends = np.array(mydf[variable_event_end])\n",
    "                        diff = (ends.astype('datetime64[us]') - starts.astype('datetime64[us]')).astype('timedelta64[D]')\n",
    "                        diff = np.nansum (diff)\n",
    "                        mydict ['total_duration_days_'+myname+'_'+myvalue] = diff.astype(int)\n",
    "        \n",
    "        \n",
    "        if total_summary_episodes >0:\n",
    "            for elem in episode_summary_variables:\n",
    "                # Calculate age at beginning and end episode\n",
    "                if variable_date_of_birth is not None and elem == variable_date_of_birth:\n",
    "                    starts = np.array(mygroup[variable_event_start])\n",
    "                    ends = np.array(mygroup[variable_event_end])\n",
    "                    bdate = mydict[variable_date_of_birth]\n",
    "                    if pd.isnull(bdate) == False:\n",
    "                        bdates = np.array([bdate] * len(starts))\n",
    "                        age_start = (starts.astype('datetime64[us]') - bdates.astype('datetime64[us]')).astype('timedelta64[Y]')\n",
    "                        age_start = age_start.astype(int)\n",
    "                        tmp = values_from_list_to_dict (age_start, 'age_start', total_summary_episodes)\n",
    "                        mydict.update(tmp)\n",
    "\n",
    "                        age_end = (ends.astype('datetime64[us]') - bdates.astype('datetime64[us]')).astype('timedelta64[Y]')\n",
    "                        age_end = age_end.astype(int)\n",
    "                        tmp = values_from_list_to_dict (age_end, 'age_end', total_summary_episodes)\n",
    "                        mydict.update(tmp)\n",
    "                else:\n",
    "                    if elem in episode_summary_variables_char:\n",
    "                        values = list(mygroup[elem])\n",
    "                        myname = sanitize_varchar(elem)\n",
    "                        tmp = values_from_list_to_dict_as_string (values, myname, total_summary_episodes)\n",
    "                        mydict.update(tmp)\n",
    "                    else:\n",
    "                        values = np.array(mygroup[elem])\n",
    "                        myname = sanitize_varchar(elem)\n",
    "                        tmp = values_from_list_to_dict (values, myname, total_summary_episodes)\n",
    "                        mydict.update(tmp)\n",
    "\n",
    "                    starts = np.array(mygroup[variable_event_start])\n",
    "                    ends = np.array(mygroup[variable_event_end])\n",
    "                    diff = (ends.astype('datetime64[us]') - starts.astype('datetime64[us]')).astype('timedelta64[D]')\n",
    "                    diff = diff.astype(int)\n",
    "                    tmp = values_from_list_to_dict (diff, 'duration_days', total_summary_episodes)\n",
    "                    mydict.update(tmp)\n",
    "        \n",
    "        \n",
    "        if total_number_of_years > 0:\n",
    "            for year_index in range(len(year_range)):\n",
    "                year = year_range[year_index]\n",
    "                year_min_date = pd.to_datetime(dt.datetime(year,1,1))\n",
    "                year_max_date = pd.to_datetime(dt.datetime(year,12,31))\n",
    "                if max_date is not None:\n",
    "                    year_max_date = min(year_max_date, max_date)\n",
    "\n",
    "                # Select episodes that end within or after this year\n",
    "                mygroup_year = mygroup.loc[mygroup[variable_event_end] >= year_min_date].copy()\n",
    "\n",
    "                # crop start and end dates of episodes that are extend outside the year\n",
    "                mygroup_year.loc[mygroup[variable_event_end] > year_max_date, variable_event_end]  = year_max_date\n",
    "                mygroup_year.loc[mygroup[variable_event_start] < year_min_date, variable_event_start]  = year_min_date\n",
    "\n",
    "                # save total number of episodes\n",
    "                mydict['year_'+str(year_index)+'_n_episodes'] = float(len(mygroup_year))\n",
    "\n",
    "                # save total duration of all episodes\n",
    "                starts = np.array(mygroup_year[variable_event_start])\n",
    "                ends = np.array(mygroup_year[variable_event_end])\n",
    "                diff = (ends.astype('datetime64[us]') - starts.astype('datetime64[us]')).astype('timedelta64[D]')\n",
    "                total_duration_days = np.nansum (diff)\n",
    "                mydict ['year_'+str(year_index)+'_duration_days'] = total_duration_days.astype(int)\n",
    "\n",
    "                # Calculate sum, mean, min and max of all numeric variables in total_summary_variables\n",
    "                for elem in total_summary_variables_num:\n",
    "                    values = np.array(mygroup_year[elem])\n",
    "                    values = values[~pd.isnull(values)]\n",
    "                    myname = sanitize_varchar(str(elem))\n",
    "                    if len(values) > 0:\n",
    "                        values = values.astype(float)\n",
    "                        mydict['year_'+str(year_index)+'_sum_'+myname] = np.sum(values)\n",
    "                        mydict['year_'+str(year_index)+'_mean_'+myname] = np.mean(values)\n",
    "                        mydict['year_'+str(year_index)+'_max_'+myname] = np.max(values)\n",
    "                        mydict['year_'+str(year_index)+'_min_'+myname] = np.min(values)\n",
    "                    else:\n",
    "                        mydict['year_'+str(year_index)+'_sum_'+myname] = np.nan\n",
    "                        mydict['year_'+str(year_index)+'_mean_'+myname] = np.nan\n",
    "                        mydict['year_'+str(year_index)+'_max_'+myname] = np.nan\n",
    "                        mydict['year_'+str(year_index)+'_min_'+myname] = np.nan\n",
    "\n",
    "                # Calculate count and duration in days of levels of all character (aka nominal) variables in total_summary_variables\n",
    "                for elem in total_summary_variables_char:\n",
    "                    res = mygroup_year[elem].value_counts()\n",
    "                    for value in res.index:\n",
    "                        if value != 'NULL':\n",
    "                            myname = sanitize_varchar(str(elem))\n",
    "                            myvalue = sanitize_varchar(str(value))\n",
    "                            mydict ['year_'+str(year_index)+'_n_'+myname+'_'+myvalue] = res.loc[value]\n",
    "\n",
    "                            # this is slow\n",
    "                            if calculate_total_duration_days_of_levels == True:\n",
    "                                mydf = mygroup[mygroup[elem] == value]\n",
    "                                starts = np.array(mydf[variable_event_start])\n",
    "                                ends = np.array(mydf[variable_event_end])\n",
    "                                diff = (ends.astype('datetime64[us]') - starts.astype('datetime64[us]')).astype('timedelta64[D]')\n",
    "                                diff = np.nansum (diff)\n",
    "                                mydict ['year_'+str(year_index)+'_duration_days_'+myname+'_'+myvalue] = diff.astype(int)\n",
    "                    \n",
    "        ret.append(mydict)\n",
    "    ret = pd.DataFrame(ret)\n",
    "    return ret\n",
    "\n",
    "# Select PPSN, Flat/Transpose & SQL Upload\n",
    "\n",
    "## Select PPSN\n",
    "datadictionary = pd.read_csv(ddictionaryfilename)\n",
    "\n",
    "variable_event_start = (datadictionary[datadictionary.EventStart == 1].Variable).tolist()[0]\n",
    "variable_event_end = (datadictionary[datadictionary.EventEnd == 1].Variable).tolist()[0]\n",
    "variable_uid = (datadictionary[datadictionary.UID == 1].Variable).tolist()[0]\n",
    "\n",
    "print ('Select %s in date %s' %(variable_uid , query_date))\n",
    "start_time = time.time()\n",
    "\n",
    "# Select UIDs (PPSNs) that have open open episode with variable_event_type (hist_lr) not variable_event_type_value (EMPL)\n",
    "sql_query_string = \"SELECT DISTINCT \" + variable_uid + \" FROM \" + jld_sql_table \n",
    "if query_date not in ['', None] and variable_event_type not in ['',None]  and variable_event_type_value not in ['',None]:\n",
    "    sql_query_string = sql_query_string + \" WHERE \" + variable_event_start + \" < \\'\" + query_date + \"\\'\"\n",
    "    sql_query_string = sql_query_string + \" and \" + variable_event_end + \" > \\'\" + query_date + \"\\'\"\n",
    "    sql_query_string = sql_query_string + \" and \" + variable_event_type + \" \"+ variable_event_type_condition + \"\\'\" + str(variable_event_type_value) + \"\\'\"\n",
    "\n",
    "print ('\\n%s\\n' %(sql_query_string))\n",
    "\n",
    "# Connect to SQL\n",
    "params = urllib.parse.quote_plus(odbc_connection_string)\n",
    "engine = create_engine('mssql+pyodbc:///?odbc_connect=%s' % params)\n",
    "conn = engine.connect().connection\n",
    "\n",
    "selected_uids = pd.read_sql_query(sql_query_string, engine)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "selected_uids = selected_uids.ppsn.tolist()\n",
    "print ('Selected %d in date %s' %(len(selected_uids), query_date))\n",
    "elapsed_time = time.time() - start_time\n",
    "print ('Elapsed time: '+ time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "\n",
    "# Transpose/Flat\n",
    "selected_variables= []\n",
    "selected_variables = datadictionary[datadictionary.EventStart == 1].Variable\n",
    "selected_variables = selected_variables.append(datadictionary[datadictionary.EventEnd == 1].Variable)\n",
    "selected_variables = selected_variables.append(datadictionary[datadictionary.DOB == 1].Variable)\n",
    "selected_variables = selected_variables.append(datadictionary[datadictionary.UID == 1].Variable)\n",
    "selected_variables = selected_variables.append(datadictionary[datadictionary.Pinfo == 1].Variable)\n",
    "selected_variables = selected_variables.append(datadictionary[datadictionary.TotalSummary == 1].Variable)\n",
    "selected_variables = selected_variables.append(datadictionary[datadictionary.EpisodeSummary == 1].Variable)\n",
    "selected_variables = list(set(selected_variables.tolist()))\n",
    "selected_variables = [x for x in selected_variables if x is not None]\n",
    "\n",
    "# Add variables used to sort episodes, if not present already\n",
    "if 'hist_lr' not in  selected_variables:\n",
    "    selected_variables.append('hist_lr')\n",
    "if 'lr_flag' not in  selected_variables:\n",
    "    selected_variables.append('lr_flag')\n",
    "\n",
    "selected_variables = ','.join(selected_variables)\n",
    "\n",
    "batch_size = int(len(selected_uids)/50)\n",
    "count = 0\n",
    "processed = 0\n",
    "flat_jld = pd.DataFrame()\n",
    "start_time = time.time()\n",
    "for batch_uids in batch(selected_uids, n=batch_size):\n",
    "    looptime = time.time()\n",
    "    uids = tuple(batch_uids)\n",
    "    \n",
    "    count = count + 1\n",
    "    print ('\\nIteration %d, processing %d %s' %(count, len(uids), variable_uid))\n",
    "    \n",
    "    # Retrieve data for selected UIDs\n",
    "    # Drop rows that have start_date >= end_date and start_date > query_date\n",
    "    print (\"\\tQuery Data\")\n",
    "    proctime = time.time()\n",
    "    sql_query_string = \"SELECT \"+ selected_variables + \" FROM \" + jld_sql_table \n",
    "    sql_query_string = sql_query_string + \" WHERE \" + variable_uid + \" IN \" + str(uids)\n",
    "    if query_date not in ['', None]:\n",
    "        sql_query_string = sql_query_string + \" and \" + variable_event_start + \" < \\'\" + query_date + \"\\'\"\n",
    "    sql_query_string = sql_query_string + \" and \" + variable_event_start + \" < \" + variable_event_end \n",
    "    \n",
    "    # Connect to SQL and retrieve data\n",
    "    params = urllib.parse.quote_plus(odbc_connection_string)\n",
    "    engine = create_engine('mssql+pyodbc:///?odbc_connect=%s' % params)\n",
    "    conn = engine.connect().connection\n",
    "\n",
    "    data = pd.read_sql_query(sql_query_string, engine)\n",
    "    \n",
    "    # Close SQL connection\n",
    "    conn.close()\n",
    "    elapsed_time = time.time() - proctime\n",
    "    print ('\\t\\tProcedure time: '+ time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "    \n",
    "    # Flat/Transpose JLD\n",
    "    print (\"\\tTranspose Data\")\n",
    "    proctime = time.time()\n",
    "    mydate =  None\n",
    "    if query_date not in ['', None]:\n",
    "        mydate = dt.datetime.strptime(query_date, '%Y%m%d')\n",
    "        \n",
    "    flat_df =  transpose_jld(data = data, \n",
    "                             dictionary= datadictionary, \n",
    "                             total_summary_episodes= n_episodes, \n",
    "                             total_number_of_years = n_years,\n",
    "                             max_date = mydate,\n",
    "                             calculate_total_duration_days_of_levels = calculate_total_duration_days_of_levels)\n",
    "    elapsed_time = time.time() - proctime\n",
    "    print ('\\t\\tProcedure time: '+ time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "    \n",
    "    # Append data\n",
    "    print (\"\\tAppend Data\")\n",
    "    proctime = time.time()\n",
    "    flat_jld = flat_jld.append(flat_df, ignore_index=True)\n",
    "    elapsed_time = time.time() - proctime\n",
    "    print ('\\t\\tProcedure time: '+ time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "\n",
    "    # Print info\n",
    "    processed = processed + len(uids)\n",
    "    print ('Processed %d/%d %s' %(processed, len(selected_uids), variable_uid))\n",
    "    elapsed_time = time.time() - looptime\n",
    "    print ('Iteration time: '+ time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "    \n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print ('Transpose/Flat Total Elapsed time: '+ time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "\n",
    "# Load into SQL\n",
    "# Connect to SQL\n",
    "mytime = time.time()\n",
    "params = urllib.parse.quote_plus(odbc_connection_string)\n",
    "engine = create_engine('mssql+pyodbc:///?odbc_connect=%s' % params)\n",
    "conn = engine.connect().connection\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Drop table if exists\n",
    "sql_string_drop = \"IF OBJECT_ID('\"+ flat_jld_sql_table + \"', 'U') IS NOT NULL\" +'\\n'+ \"DROP TABLE \" + flat_jld_sql_table\n",
    "cursor.execute(sql_string_drop)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "# Connect to SQL\n",
    "params = urllib.parse.quote_plus(odbc_connection_string)\n",
    "engine = create_engine('mssql+pyodbc:///?odbc_connect=%s' % params)\n",
    "conn = engine.connect().connection\n",
    "\n",
    "# SpeedUp For fast execution of mutiple row \n",
    "@event.listens_for(engine, 'before_cursor_execute')\n",
    "def receive_before_cursor_execute(conn, cursor, statement, params, context, executemany):\n",
    "    if executemany:\n",
    "        cursor.fast_executemany = True\n",
    "\n",
    "#upload data\n",
    "print('\\nUploading to SQL')\n",
    "sql_chunksize = 10000\n",
    "flat_jld.to_sql(flat_jld_sql_table, engine, if_exists='append', index=False, chunksize=sql_chunksize)\n",
    "#Close SQL Connection\n",
    "conn.close()\n",
    "\n",
    "elapsed_time = time.time() - mytime\n",
    "print ('Upload time: '+ time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "\n",
    "print ('\\nALL DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
